{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6504bb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Takumi\\anaconda3\\envs\\AI2\\lib\\site-packages\\ale_py\\roms\\utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "  for external in metadata.entry_points().get(self.group, []):\n",
      "C:\\Users\\Takumi\\anaconda3\\envs\\AI2\\lib\\site-packages\\quaternion\\numba_wrapper.py:23: UserWarning: \n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Could not import from numba, which means that some\n",
      "parts of this code may run MUCH more slowly.  You\n",
      "may wish to install numba.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "  warnings.warn(warning_text)\n",
      "2022-04-05 20:40:28,583\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "2022-04-05 20:40:28,585\tINFO ppo.py:250 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "2022-04-05 20:40:28,585\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 20:40:53,403\tINFO trainable.py:130 -- Trainable.setup took 24.822 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2022-04-05 20:40:53,405\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 20:41:05,437\tINFO trainable.py:130 -- Trainable.setup took 11.988 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2022-04-05 20:41:05,439\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "import argparse\n",
    "import gym\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.logger import Logger, UnifiedLogger, pretty_print\n",
    "from ray.rllib.env.multi_agent_env import make_multi_agent\n",
    "from ray.rllib.examples.models.shared_weights_model import TF2SharedWeightsModel\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.utils.framework import try_import_tf\n",
    "from ray.rllib.utils.test_utils import check_learning_achieved\n",
    "from ray.rllib.agents.ppo import ppo, PPOTrainer, PPOTFPolicy\n",
    "from ray.rllib.agents.a3c.a3c_tf_policy import A3CTFPolicy\n",
    "from ray.rllib.agents.a3c import a3c\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "from environment_rllib_3d1 import MyEnv\n",
    "#from test_env_for_lstm import MyEnv\n",
    "from settings.initial_settings import *\n",
    "from settings.reset_conditions import reset_conditions\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from modules.savers import save_conditions\n",
    "from utility.result_env import render_env\n",
    "from utility.terminate_uavsimproc import teminate_proc\n",
    "from utility.latest_learned_file_path import latest_learned_file_path\n",
    "from utility.read_wright_weights import save_weights\n",
    "from utility.read_wright_weights import reload_weights\n",
    "from utility.save_logs import save_logs\n",
    "from utility.save_logs import save_hists\n",
    "from utility.save_logs import save_env_info\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import ctypes\n",
    "import warnings\n",
    "\n",
    "#UCAV.exeが起動している場合、プロセスキルする。\n",
    "teminate_proc.UAVsimprockill(proc_name=\"UCAV.exe\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n",
    "warnings.filterwarnings('ignore', category=matplotlib.MatplotlibDeprecationWarning)\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "PROJECT = \"UCAV\"\n",
    "TRIAL_ID = 2\n",
    "TRIAL = 'test_' + str(TRIAL_ID)\n",
    "EVAL_FREQ = 1\n",
    "CONTINUAL = True\n",
    "NUM_EVAL = 1\n",
    "def custom_log_creator(custom_path, custom_str):\n",
    "    timestr = datetime.datetime.today().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    logdir_prefix = \"{}_{}\".format(custom_str, timestr)\n",
    "\n",
    "    def logger_creator(config):\n",
    "        if not os.path.exists(custom_path):\n",
    "            os.makedirs(custom_path)\n",
    "        logdir = tempfile.mkdtemp(prefix=logdir_prefix, dir=custom_path)\n",
    "        return UnifiedLogger(config, logdir, loggers=None)\n",
    "\n",
    "    return logger_creator\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(ignore_reinit_error=True, log_to_driver=False)\n",
    "\n",
    "#ModelCatalog.register_custom_model('my_model', MyRNNUAVClass)\n",
    "\n",
    "eval_env = MyEnv()\n",
    "policies_own = {\n",
    "    \"blue_0\": (PPOTFPolicy, eval_env.observation_space, eval_env.action_space,\n",
    "               {\"model\":{\"vf_share_layers\": False,\"use_lstm\": True,\"max_seq_len\": 200},\n",
    "               \"exploration_config\": {\"type\": \"StochasticSampling\",\"random_timesteps\":0},\"explore\":True,}),\n",
    "    \"blue_1\": (PPOTFPolicy, eval_env.observation_space, eval_env.action_space,\n",
    "               {\"model\":{\"vf_share_layers\": False,\"use_lstm\": True,\"max_seq_len\": 200},\n",
    "               \"exploration_config\": {\"type\": \"StochasticSampling\",\"random_timesteps\":0},\"explore\":True,}),\n",
    "    \"red_0\": (PPOTFPolicy, eval_env.observation_space, eval_env.action_space,\n",
    "              {\"model\":{\"vf_share_layers\": False,\"use_lstm\": True,\"max_seq_len\": 200},\"explore\":False,}),\n",
    "    \"red_1\": (PPOTFPolicy, eval_env.observation_space, eval_env.action_space,\n",
    "              {\"model\":{\"vf_share_layers\": False,\"use_lstm\": True,\"max_seq_len\": 200},\"explore\":False,}),\n",
    "}\n",
    "policies_enem = {\n",
    "    \"red_0\": (PPOTFPolicy, eval_env.observation_space, eval_env.action_space,\n",
    "              {\"model\":{\"vf_share_layers\": False,\"use_lstm\": True,\"max_seq_len\": 200},\"explore\":False,}),\n",
    "    \"red_1\": (PPOTFPolicy, eval_env.observation_space, eval_env.action_space,\n",
    "              {\"model\":{\"vf_share_layers\": False,\"use_lstm\": True,\"max_seq_len\": 200},\"explore\":False,}),\n",
    "}\n",
    "# policy_ids = list(policies.keys())\n",
    "\n",
    "def policy_mapping_fn(agent_id, episode, **kwargs):\n",
    "    #print(agent_id,episode)\n",
    "    #pol_id = policy_ids[agent_id]\n",
    "\n",
    "    pol_id = agent_id\n",
    "    return pol_id\n",
    "\n",
    "# Instanciate the evaluation env\n",
    "config_own = ppo.DEFAULT_CONFIG.copy()\n",
    "config_own = {\"env\": MyEnv,\"num_gpus\": 1,\"num_workers\": 0, \"num_cpus_per_worker\": 0,\"num_gpus_per_worker\": 1,\n",
    "          \"train_batch_size\": 1200*25,\n",
    "          \"batch_mode\": \"complete_episodes\",\n",
    "          \"gamma\":0.995, \"lr\": 2.5e-4,\"shuffle_sequences\": True,\n",
    "          \"observation_space\":eval_env.observation_space,\"action_space\":eval_env.action_space,\n",
    "          \"sgd_minibatch_size\": 600, \"num_sgd_iter\":20,\n",
    "          \"multiagent\": {\"policies\": policies_own,  \"policy_mapping_fn\": policy_mapping_fn}\n",
    "         }\n",
    "config_enem = ppo.DEFAULT_CONFIG.copy()\n",
    "config_enem = {\"env\": MyEnv,\"num_gpus\": 1,\"num_workers\": 0, \"num_cpus_per_worker\": 0,\"num_gpus_per_worker\": 1,\n",
    "          \"train_batch_size\": 600*5*10,\n",
    "          \"batch_mode\": \"complete_episodes\",\n",
    "          \"gamma\":0.995, \"lr\": 2.5e-4,\"shuffle_sequences\": True,\n",
    "          \"observation_space\":eval_env.observation_space,\"action_space\":eval_env.action_space,\n",
    "          \"sgd_minibatch_size\": 600, \"num_sgd_iter\":20,\n",
    "          \"multiagent\": {\"policies\": policies_enem,  \"policy_mapping_fn\": policy_mapping_fn}\n",
    "         }\n",
    "\n",
    "res_name = \"test\"\n",
    "conditions_dir = os.path.join('./' + PROJECT + '/conditions/')\n",
    "\n",
    "if not os.path.exists(conditions_dir):\n",
    "    os.makedirs(conditions_dir)\n",
    "save_conditions(conditions_dir)\n",
    "\n",
    "# PPOTrainer()は、try_import_tfを使うと、なぜかTensorflowのeager modeのエラーになる。\n",
    "\n",
    "trainer = ppo.PPOTrainer(config=config_own,\n",
    "                         logger_creator=custom_log_creator(\n",
    "                             os.path.expanduser(\"./\" + PROJECT + \"/logs\"), TRIAL))\n",
    "\n",
    "adversary = ppo.PPOTrainer(config=config_enem,\n",
    "                         logger_creator=custom_log_creator(\n",
    "                             os.path.expanduser(\"./\" + PROJECT + \"/logs\"), TRIAL))\n",
    "\n",
    "if CONTINUAL:\n",
    "    # Continual learning: Need to specify the checkpoint\n",
    "    # model_path = PROJECT + '/checkpoints/' + TRIAL + '/checkpoint_000197/checkpoint-197'\n",
    "    model_path = latest_learned_file_path('./UCAV/checkpoints/test_2/*')\n",
    "    \n",
    "    #trainer.restore(checkpoint_path=model_path)\n",
    "    #save_weights(\"blue_0\",trainer)\n",
    "    #save_weights(\"blue_1\",trainer)\n",
    "\n",
    "    reload_weights(policy_id=\"red_0\",trainer=trainer,set_policy_id=\"blue_0\")\n",
    "    reload_weights(policy_id=\"red_1\",trainer=trainer,set_policy_id=\"blue_1\")\n",
    "    reload_weights(policy_id=\"blue_0\",trainer=trainer,set_policy_id=\"blue_0\")\n",
    "    reload_weights(policy_id=\"blue_1\",trainer=trainer,set_policy_id=\"blue_1\")\n",
    "    save_weights(\"red_0\",trainer)\n",
    "    save_weights(\"red_1\",trainer)\n",
    "\n",
    "\n",
    "models_dir = os.path.join('./' + PROJECT + '/models/')\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "hist_dir = os.path.join('./' + PROJECT + '/hist/')\n",
    "if not os.path.exists(hist_dir):\n",
    "    os.makedirs(hist_dir)\n",
    "for j in range(2):\n",
    "    text_name = models_dir + TRIAL + \"blue_\"+str(j) +'.txt'\n",
    "    with open(text_name, \"w\") as fp:\n",
    "        trainer.get_policy(\"blue_\"+str(j)).model.base_model.summary(print_fn=lambda x: fp.write(x + \"\\r\\n\"))\n",
    "    png_name = models_dir + TRIAL + '.png'\n",
    "    plot_model(trainer.get_policy(\"blue_\"+str(j)).model.base_model, to_file=png_name, show_shapes=True)\n",
    "\n",
    "\n",
    "\n",
    "# Define checkpoint dir\n",
    "check_point_dir = os.path.join('./' + PROJECT + '/checkpoints/', TRIAL)\n",
    "if not os.path.exists(check_point_dir):\n",
    "    os.makedirs(check_point_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ebbfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "\n",
      "----------------- Training at steps:0 start! -----------------\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "700 blue_1 Shoot at red_1 launch distance : 58925.86365711398 True True\n",
      "723 blue_1 Shoot at red_1 launch distance : 49626.04795902315 True True\n",
      "803 blue_1 Splash :red_1\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 1200 0.899000535029211 -54.30947538676721\n",
      "blue_1 False False 1200 0.9990005350292109 65.08631124312076\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "292 blue_0 Shoot at red_1 launch distance : 59194.11408202614 True True\n",
      "320 blue_0 Shoot at red_1 launch distance : 47532.873524210874 True True\n",
      "339 red_1 Shoot at blue_0\n",
      "350 red_1 Shoot at blue_0\n",
      "365 blue_0 Splash :red_1\n",
      "Same tgt shoot\n",
      "Same tgt shoot\n",
      "619 blue_1 Shoot at red_0 launch distance : 58485.9791042194 True True\n",
      "Same tgt shoot\n",
      "Same tgt shoot\n",
      "630 blue_1 Shoot at red_0 launch distance : 52405.53968990179 True True\n",
      "699 blue_1 Splash :red_0\n",
      "WIN\n",
      "blue_0 False True 699 12.217058800247992 104.82732942984501\n",
      "blue_1 False True 699 25.650535195097778 89.020462625608\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "267 blue_1 Shoot at red_1 launch distance : 58672.882005178 True True\n",
      "284 blue_1 Shoot at red_1 launch distance : 51598.86079875764 True True\n",
      "308 blue_0 Shoot at red_1 launch distance : 56677.52162927349 True True\n",
      "330 blue_0 Shoot at red_1 launch distance : 47231.73065705831 True True\n",
      "337 blue_1 Splash :red_1\n",
      "498 red_0 Shoot at blue_1\n",
      "509 red_0 Shoot at blue_1\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 1200 0.8990000880212764 9.585935170598898\n",
      "blue_1 False False 1200 1.0000000880212765 99.35959612500018\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "269 blue_1 Shoot at red_1 launch distance : 59383.05203402511 True True\n",
      "290 blue_1 Shoot at red_1 launch distance : 48827.81829634073 True True\n",
      "356 blue_1 Splash :red_1\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 1200 0.9969994668474607 0.7839387657375675\n",
      "blue_1 False False 1200 0.9989994668474607 121.98351616611193\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "281 blue_1 Shoot at red_1 launch distance : 59570.17095149916 True True\n",
      "293 blue_1 Shoot at red_1 launch distance : 54163.60113318781 True True\n",
      "301 blue_0 Shoot at red_1 launch distance : 58780.8867518723 True True\n",
      "328 blue_0 Shoot at red_1 launch distance : 46660.59535001178 True True\n",
      "343 red_1 Shoot at blue_0\n",
      "354 red_1 Shoot at blue_0\n",
      "359 blue_1 Splash :red_1\n",
      "483 blue_0 DOWN\n",
      "1144 blue_1 DOWN\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 1144 0.8989994308308517 46.69995826276564\n",
      "blue_1 False False 1144 -0.10100056916914824 77.39515493078392\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "284 blue_0 Shoot at red_1 launch distance : 57661.988779380044 True True\n",
      "318 blue_0 Shoot at red_1 launch distance : 42534.202841521845 True True\n",
      "318 blue_1 Shoot at red_1 launch distance : 51834.95279280061 True True\n",
      "324 red_1 Shoot at blue_0\n",
      "335 red_1 Shoot at blue_0\n",
      "349 blue_1 Shoot at red_1 launch distance : 40010.14893642944 True True\n",
      "360 blue_0 Splash :red_1\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 1200 0.9989997037403698 61.18784935058501\n",
      "blue_1 False False 1200 0.8989997037403699 11.94518341725184\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "619 blue_1 DOWN\n",
      "638 blue_0 Shoot at red_1 launch distance : 58682.5159187081 True True\n",
      "675 blue_0 Shoot at red_1 launch distance : 44087.33389533114 True True\n",
      "731 red_1 Shoot at blue_0\n",
      "742 red_1 Shoot at blue_0\n",
      "774 blue_0: Destroyed\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 774 0.35617011063409176 81.72857149129173\n",
      "blue_1 False False 774 0.3990004773007584 -2.0616489183264717\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "189 blue_0 DOWN\n",
      "886 blue_1 Shoot at red_1 launch distance : 56508.50011624679 True True\n",
      "906 red_0 Shoot at blue_1\n",
      "907 blue_1 Shoot at red_1 launch distance : 50014.80419208571 True True\n",
      "917 red_0 Shoot at blue_1\n",
      "981 red_1 Shoot at blue_1\n",
      "996 blue_1: Destroyed\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 996 0.39899907668875956 -1.0058604881789917\n",
      "blue_1 False False 996 0.3542295766887596 37.84431207363502\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "180 blue_0 DOWN\n",
      "287 blue_1 Shoot at red_1 launch distance : 59558.69100189892 True True\n",
      "296 blue_1 DOWN\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 296 -0.10100159849129828 -1.3050528871721303\n",
      "blue_1 False False 296 -0.704989965157965 14.922821075876522\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "268 blue_1 Shoot at red_1 launch distance : 59262.24194888871 True True\n",
      "305 blue_1 Shoot at red_1 launch distance : 40558.2822901083 True True\n",
      "339 blue_0 Shoot at red_1 launch distance : 55510.0074924044 True True\n",
      "340 blue_1 Splash :red_1\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 1200 1.0000035115438066 2.371816211026065\n",
      "blue_1 False False 1200 0.8990010115438066 44.32289494043776\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "285 blue_0 Shoot at red_1 launch distance : 57660.051895203826 True True\n",
      "311 blue_0 Shoot at red_1 launch distance : 47253.45972202961 True True\n",
      "330 red_1 Shoot at blue_0\n",
      "365 blue_0 Splash :red_1\n",
      "395 blue_0: Destroyed\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 1200 0.8990000453429445 73.95203798380462\n",
      "blue_1 False False 1200 0.8990000453429445 1.8778375357788888\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "286 blue_1 Shoot at red_1 launch distance : 59858.69446036659 True True\n",
      "299 blue_1 Shoot at red_1 launch distance : 54333.05327317348 True True\n",
      "325 blue_0 Shoot at red_1 launch distance : 55821.90067834659 True True\n",
      "341 blue_0 Shoot at red_1 launch distance : 47712.89377921586 True True\n",
      "356 red_1 Shoot at blue_0\n",
      "357 blue_1 Splash :red_1\n",
      "575 red_0 Shoot at blue_1\n",
      "594 red_0 Shoot at blue_0\n",
      "640 blue_1: Destroyed\n",
      "694 blue_0: Destroyed\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False True 694 0.8570611473035337 73.33390449853786\n",
      "blue_1 False True 694 0.8989998473035337 103.79856344026051\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "213 blue_1 DOWN\n",
      "291 blue_0 DOWN\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 291 -1.1010086345784837 -1.4049181395849022\n",
      "blue_1 False False 291 -0.10100023457848371 -1.506497893112372\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295 blue_1 Shoot at red_1 launch distance : 59556.55081438123 True True\n",
      "309 blue_1 Shoot at red_1 launch distance : 53458.789531332484 True True\n",
      "353 blue_0 Shoot at red_1 launch distance : 59845.5904790344 True True\n",
      "371 blue_1 Splash :red_1\n",
      "530 red_0 Shoot at blue_1\n",
      "541 red_0 Shoot at blue_1\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 1200 0.8989997452417609 -3.657025056358102\n",
      "blue_1 False False 1200 0.8989997452417609 95.16997863905986\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "225 blue_0 DOWN\n",
      "298 blue_1 Shoot at red_1 launch distance : 59940.76051676992 True True\n",
      "315 blue_1 Shoot at red_1 launch distance : 54293.56933489817 True True\n",
      "361 red_1 Shoot at blue_1\n",
      "372 red_1 Shoot at blue_1\n",
      "437 blue_1: Destroyed\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 437 -0.10099997139185694 -2.3226646779619\n",
      "blue_1 False False 437 0.3589153619414764 72.70646016512937\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "254 blue_1 DOWN\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 1200 -0.10099896252401744 -56.4455114219405\n",
      "blue_1 False False 1200 -0.10099896252401744 5.91391320767643\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "287 blue_1 Shoot at red_1 launch distance : 59757.26194440865 True True\n",
      "311 blue_1 Shoot at red_1 launch distance : 47208.33349054784 True True\n",
      "312 blue_0 Shoot at red_1 launch distance : 59484.87482082465 True True\n",
      "337 blue_0 Shoot at red_1 launch distance : 48565.47740285422 True True\n",
      "367 blue_1 Splash :red_1\n",
      "970 blue_0 DOWN\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 1200 0.8989997464561744 42.30290763547218\n",
      "blue_1 False False 1200 0.9989997464561745 98.61735828499909\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "922 blue_1 DOWN\n",
      "1182 blue_0 DOWN\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 1182 -1.1009989845200647 -18.27884468426998\n",
      "blue_1 False False 1182 -0.10099898452006476 -13.217780151922481\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 1200 -0.10100029602990511 -50.67069181946316\n",
      "blue_1 False False 1200 -0.10100029602990511 -36.51369208612982\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 1200 -0.10099905645565245 -24.598110516428072\n",
      "blue_1 False False 1200 -0.10099905645565245 -9.226111916428026\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "329 blue_1 Shoot at red_1 launch distance : 59362.69932492866 True True\n",
      "355 blue_1 Shoot at red_1 launch distance : 57560.75723027361 True True\n",
      "463 blue_1 Splash :red_1\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 1200 0.8989993682139578 -33.06717471213331\n",
      "blue_1 False False 1200 0.9989993682139577 74.24241020104154\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "186 blue_0 DOWN\n",
      "383 blue_1 Shoot at red_0 launch distance : 53743.63952310573 True True\n",
      "424 red_0 Shoot at blue_1\n",
      "434 blue_1 DOWN\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 434 0.3989993466192818 -0.9052949083799524\n",
      "blue_1 False False 434 -0.4070006533807181 25.01763906958625\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "261 blue_1 Shoot at red_1 launch distance : 56236.049536463266 True True\n",
      "286 blue_0 Shoot at red_1 launch distance : 57014.359151454126 True True\n",
      "290 blue_1 Shoot at red_1 launch distance : 41107.78998618463 True True\n",
      "313 blue_0 Shoot at red_1 launch distance : 42392.85929383645 True True\n",
      "318 red_1 Shoot at blue_0\n",
      "327 blue_1 Splash :red_1\n",
      "357 blue_0: Destroyed\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 1200 0.8990009575817663 47.07069558751718\n",
      "blue_1 False False 1200 0.8990009575817663 38.49130927672797\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "335 blue_0 Shoot at red_1 launch distance : 59298.16872216707 True True\n",
      "356 blue_1 Shoot at red_1 launch distance : 59718.50747618825 True True\n",
      "375 blue_0 Shoot at red_1 launch distance : 43723.4779862554 True True\n",
      "391 red_1 Shoot at blue_0\n",
      "394 blue_1 Shoot at red_1 launch distance : 46145.06411421596 True True\n",
      "402 red_1 Shoot at blue_0\n",
      "412 blue_0 Splash :red_1\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 1200 0.899001331532467 77.67904289019864\n",
      "blue_1 False False 1200 0.899001331532467 19.102796571752243\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "296 blue_0 Shoot at red_1 launch distance : 59683.8510759032 True True\n",
      "317 blue_0 Shoot at red_1 launch distance : 50740.42657024641 True True\n",
      "319 blue_1 Shoot at red_1 launch distance : 59519.04050592137 True True\n",
      "340 red_1 Shoot at blue_0\n",
      "358 blue_1 Shoot at red_1 launch distance : 44139.537572857356 True True\n",
      "377 blue_0 Splash :red_1\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 1200 0.9990003018665092 90.15387212498808\n",
      "blue_1 False False 1200 0.8990003018665093 20.562822479630068\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "297 blue_1 Shoot at red_1 launch distance : 59970.14832649247 True True\n",
      "308 blue_1 Shoot at red_1 launch distance : 55704.86238216501 True True\n",
      "369 blue_1 Splash :red_1\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 1200 0.9990062879497755 -12.227611080947295\n",
      "blue_1 False False 1200 0.8990008212831089 123.2488632930365\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "279 blue_1 Shoot at red_1 launch distance : 56096.744746174416 True True\n",
      "293 blue_1 Shoot at red_1 launch distance : 50256.210845470276 True True\n",
      "349 blue_1 Splash :red_1\n",
      "382 red_0 Shoot at blue_1\n",
      "733 blue_1 DOWN\n",
      "897 blue_0 DOWN\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 897 -0.1010013488661925 -1.7663576714642886\n",
      "blue_1 False False 897 0.8990007844671408 75.17962155366037\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "284 blue_1 Shoot at red_1 launch distance : 59820.73890420267 True True\n",
      "294 blue_0 Shoot at red_1 launch distance : 58773.322493492684 True True\n",
      "304 blue_1 Shoot at red_1 launch distance : 51112.56088426213 True True\n",
      "318 blue_0 Shoot at red_1 launch distance : 47323.44281841838 True True\n",
      "333 red_1 Shoot at blue_0\n",
      "344 red_1 Shoot at blue_0\n",
      "357 blue_1 Splash :red_1\n",
      "378 blue_0: Destroyed\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 1200 0.8990000666350105 60.01285719133346\n",
      "blue_1 False False 1200 0.9990000666350105 75.61855583775777\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "274 blue_1 Shoot at red_1 launch distance : 59136.279801382014 True True\n",
      "311 blue_0 Shoot at red_1 launch distance : 59644.32329358768 True True\n",
      "339 blue_0 Shoot at red_1 launch distance : 47493.68034217279 True True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395 blue_1 Shoot at red_1 launch distance : 27622.694989399475 True True\n",
      "423 blue_0 Splash :red_1\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 1200 0.9990100685730191 80.66040242936\n",
      "blue_1 False False 1200 0.8990015685730192 45.39393166411194\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n",
      "658 blue_1 Shoot at red_0 launch distance : 57192.18478356483 True True\n",
      "681 blue_1 Shoot at red_0 launch distance : 46659.73841544922 True True\n",
      "694 blue_0 Shoot at red_0 launch distance : 59627.257689269485 True True\n",
      "716 blue_0 Shoot at red_0 launch distance : 49965.399111439765 True True\n",
      "733 blue_1 Splash :red_0\n",
      "978 red_1 Shoot at blue_0\n",
      "989 red_1 Shoot at blue_0\n",
      "1056 blue_0: Destroyed\n",
      "TIME LIMIT LOSE\n",
      "blue_0 False False 1200 0.8989990149779956 39.50014509189346\n",
      "blue_1 False False 1200 0.8989990149779956 19.499243460335766\n",
      "==============================================================\n",
      "-------------------------- Scene: 0 --------------------------\n",
      "==============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eval_env.reset()\n",
    "save_env_info(eval_env)\n",
    "record_mode = 0\n",
    "results_dir = os.path.join('./' + PROJECT + '/results/')\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "results_file = results_dir + TRIAL + '.pkl'\n",
    "\n",
    "best_reward = {\"blue_0\":0,\"blue_1\":0}\n",
    "for steps in range(10001):\n",
    "    # Training\n",
    "    print(f'\\n----------------- Training at steps:{steps} start! -----------------')\n",
    "    eval_env.eval = False\n",
    "    eval_env.self_play = True\n",
    "    eval_env.reset()\n",
    "    results = trainer.train()\n",
    "    save_logs(res_name,results,steps,CONTINUAL)\n",
    "    print(pretty_print(results))\n",
    "    check_point = trainer.save(checkpoint_dir=check_point_dir)\n",
    "    # Evaluation\n",
    "    if steps % EVAL_FREQ == 0:\n",
    "        print(f'\\n-------------- Evaluation at steps:{steps} starting ! --------------')\n",
    "        EVAL_reward = {\"blue_0\":0,\"blue_1\":0}\n",
    "        #check_point = trainer.save(checkpoint_dir=check_point_dir)\n",
    "        for i in range(NUM_EVAL):\n",
    "            # print(f'\\nEvaluation {i}:')\n",
    "            #model_path = latest_learned_file_path('./UCAV/checkpoints/test_2/*')\n",
    "            #trainer.restore(checkpoint_path=model_path)\n",
    "            eval_env.eval = True\n",
    "            obs = eval_env.reset()\n",
    "            done = False\n",
    "            \n",
    "            step_num = 0\n",
    "            #fig = plt.figure(1,figsize=(8.0, 6.0))\n",
    "            ESC = 0x1B          # ESCキーの仮想キーコード\n",
    "            trajectory_length = 100\n",
    "\n",
    "            cell_size = 256\n",
    "            state_0=[np.zeros(cell_size, np.float32),np.zeros(cell_size, np.float32)]\n",
    "            state_1=[np.zeros(cell_size, np.float32),np.zeros(cell_size, np.float32)]\n",
    "            state_2=[np.zeros(cell_size, np.float32),np.zeros(cell_size, np.float32)]\n",
    "            state_3=[np.zeros(cell_size, np.float32),np.zeros(cell_size, np.float32)]\n",
    "            action_dict0 = [0,0]\n",
    "            action_dict1 = [0,0]\n",
    "            action_dict2 = [0,0]\n",
    "            action_dict3 = [0,0]\n",
    "            rewards = {\"blue_0\":0,\"blue_1\":0}\n",
    "            if record_mode == 0:\n",
    "                file_name = \"test_num\" + str(steps) +str(i)\n",
    "                #video = cv2.VideoWriter(file_name+'.mp4',0x00000020,20.0,(800,600))\n",
    "\n",
    "            while True:\n",
    "                action_dict = {}\n",
    "                action_dict0 = trainer.compute_single_action(obs[\"blue_0\"],\n",
    "                                                             state=state_0,prev_action=None,prev_reward=None,\n",
    "                                                             policy_id=\"blue_0\",explore=False)\n",
    "                action_dict1 = trainer.compute_single_action(obs[\"blue_1\"],\n",
    "                                                             state=state_1,prev_action=None,prev_reward=None,\n",
    "                                                             policy_id=\"blue_1\",explore=False)\n",
    "                action_dict2 = trainer.compute_single_action(obs[\"red_0\"],\n",
    "                                                             state=state_2,prev_action=None,prev_reward=None,\n",
    "                                                             policy_id=\"red_0\",explore=False)\n",
    "                action_dict3 = trainer.compute_single_action(obs[\"red_1\"],\n",
    "                                                             state=state_3,prev_action=None,prev_reward=None,\n",
    "                                                             policy_id=\"red_1\",explore=False)\n",
    "                \n",
    "                #action_dict0 = trainer.compute_single_action(obs[\"blue_0\"],policy_id=\"blue_0\")\n",
    "                #action_dict1 = trainer.compute_single_action(obs[\"blue_1\"],policy_id=\"blue_1\")\n",
    "                state_0 = action_dict0[1]\n",
    "                state_1 = action_dict1[1]\n",
    "                state_2 = action_dict2[1]\n",
    "                state_3 = action_dict3[1]\n",
    "                obs, rewards, dones, infos = eval_env.step({\"blue_0\": action_dict0[0],\n",
    "                                                            \"blue_1\": action_dict1[0],\n",
    "                                                            \"red_0\": action_dict2[0],\n",
    "                                                            \"red_1\": action_dict3[0],})\n",
    "\n",
    "                env_blue_pos_temp_mod, env_red_pos_temp_mod, env_mrm_pos_temp_mod = render_env.copy_from_env_mod(eval_env)\n",
    "                if eval_env.timer == 1:\n",
    "                    env_blue_pos_mod = env_blue_pos_temp_mod\n",
    "                    env_red_pos_mod = env_red_pos_temp_mod\n",
    "                    env_mrm_pos_mod = env_mrm_pos_temp_mod\n",
    "                else:\n",
    "                    env_blue_pos_mod = np.vstack([env_blue_pos_mod,env_blue_pos_temp_mod])\n",
    "                    env_red_pos_mod = np.vstack([env_red_pos_mod,env_red_pos_temp_mod])\n",
    "                    env_mrm_pos_mod = np.vstack([env_mrm_pos_mod,env_mrm_pos_temp_mod])\n",
    "                EVAL_reward[\"blue_0\"] += rewards[\"blue_0\"]\n",
    "                EVAL_reward[\"blue_1\"] += rewards[\"blue_1\"]\n",
    "                # plt.clf()\n",
    "\n",
    "                # plt.subplots_adjust(left=-0.1,right=1.1,bottom=-0.1,top=1.1)\n",
    "                # fig.canvas.draw()\n",
    "                # plt.pause(.01)\n",
    "\n",
    "                #if record_mode == 0:\n",
    "                    #img = np.array(fig.canvas.renderer.buffer_rgba())\n",
    "                    #img = cv2.cvtColor(img, cv2.COLOR_RGBA2BGR)\n",
    "                    #video.write(img.astype('uint8'))\n",
    "\n",
    "                \n",
    "                step_num = step_num + 1\n",
    "                \n",
    "                done = dones[\"__all__\"]\n",
    "                \n",
    "                #print(f'rewards:{rewards}')\n",
    "                #if record_mode == 0:\n",
    "                #    img = eval_env.render_movie(file_name,step_num)\n",
    "                #    video.write(img.astype('unit8'))\n",
    "                #elif record_mode == 1:\n",
    "                #    eval_env.render()\n",
    "                #elif record_mode == 2:\n",
    "                #    eval_env.render()\n",
    "                    \n",
    "                #env_blue_pos_temp, env_red_pos_temp, env_mrm_pos_temp = render_env.copy_from_env(eval_env)\n",
    "                \n",
    "                #env_blue_pos.append(env_blue_pos_temp)\n",
    "                #env_red_pos.append(env_red_pos_temp)\n",
    "                #env_mrm_pos.append(env_mrm_pos_temp)\n",
    "                #step_num = step_num + 1\n",
    "                # エピソードの終了処理\n",
    "                if dones['__all__']:\n",
    "                    save_hists(\"blue_\"+str(i),steps,env_blue_pos_mod,hist_dir)\n",
    "                    save_hists(\"red_\"+str(i),steps,env_red_pos_mod,hist_dir)\n",
    "                    save_hists(\"mrm_\"+str(i),steps,env_mrm_pos_mod,hist_dir)\n",
    "                    # print(f'all done at {env.steps}')\n",
    "                    break\n",
    "            if EVAL_reward[\"blue_0\"]> best_reward[\"blue_0\"]:\n",
    "                save_weights(\"blue_0\",trainer)\n",
    "                reload_weights(policy_id=\"red_0\",trainer=trainer,set_policy_id=\"blue_0\")\n",
    "                best_reward[\"blue_0\"] = EVAL_reward[\"blue_0\"]\n",
    "            if EVAL_reward[\"blue_1\"]> best_reward[\"blue_1\"]:\n",
    "                save_weights(\"blue_1\",trainer)\n",
    "                reload_weights(policy_id=\"red_1\",trainer=trainer,set_policy_id=\"blue_1\")\n",
    "                best_reward[\"blue_1\"] = EVAL_reward[\"blue_1\"]\n",
    "\n",
    "            \n",
    "            #if record_mode == 0:\n",
    "               # video.release()\n",
    "\n",
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208637a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "import argparse\n",
    "import gym\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.logger import Logger, UnifiedLogger, pretty_print\n",
    "from ray.rllib.env.multi_agent_env import make_multi_agent\n",
    "from ray.rllib.examples.models.shared_weights_model import TF2SharedWeightsModel\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.utils.framework import try_import_tf\n",
    "from ray.rllib.utils.test_utils import check_learning_achieved\n",
    "from ray.rllib.agents.ppo import ppo\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from environment_rllib_3d import MyEnv\n",
    "from settings.initial_settings import *\n",
    "from settings.reset_conditions import reset_conditions\n",
    "#from modules.models import MyConv2DModel_v0B_Small_CBAM_1DConv_Share\n",
    "from modules.models import DenseNetModelLarge\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from modules.savers import save_conditions\n",
    "from utility.result_env import render_env\n",
    "from utility.terminate_uavsimproc import teminate_proc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import ctypes\n",
    "import warnings\n",
    "\n",
    "#UCAV.exeが起動している場合、プロセスキルする。\n",
    "teminate_proc.UAVsimprockill(proc_name=\"UCAV_100.exe\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n",
    "warnings.filterwarnings('ignore', category=matplotlib.MatplotlibDeprecationWarning)\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "PROJECT = \"UCAV\"\n",
    "TRIAL_ID = 2\n",
    "TRIAL = 'test_' + str(TRIAL_ID)\n",
    "EVAL_FREQ = 10\n",
    "CONTINUAL = True\n",
    "\n",
    "def custom_log_creator(custom_path, custom_str):\n",
    "    timestr = datetime.datetime.today().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    logdir_prefix = \"{}_{}\".format(custom_str, timestr)\n",
    "\n",
    "    def logger_creator(config):\n",
    "        if not os.path.exists(custom_path):\n",
    "            os.makedirs(custom_path)\n",
    "        logdir = tempfile.mkdtemp(prefix=logdir_prefix, dir=custom_path)\n",
    "        return UnifiedLogger(config, logdir, loggers=None)\n",
    "\n",
    "    return logger_creator\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(ignore_reinit_error=True, log_to_driver=False)\n",
    "\n",
    "ModelCatalog.register_custom_model('my_model', DenseNetModelLarge)\n",
    "\n",
    "# config = {\"env\": MyEnv,\n",
    "#           \"num_workers\": NUM_WORKERS,\n",
    "#           \"num_gpus\": NUM_GPUS,\n",
    "#           \"num_cpus_per_worker\": NUM_CPUS_PER_WORKER,\n",
    "#           \"num_sgd_iter\": NUM_SGD_ITER,\n",
    "#           \"lr\": LEARNING_RATE,\n",
    "#           \"gamma\": GAMMA,  # default=0.99\n",
    "#           \"model\": {\"custom_model\": \"my_model\"}\n",
    "#           # \"framework\": framework\n",
    "#           }  # use tensorflow 2\n",
    "config = {\"env\": MyEnv,\"num_gpus\": 0,\"num_workers\": 0, \"num_cpus_per_worker\": 0,\"num_gpus\": 0}\n",
    "conditions_dir = os.path.join('./' + PROJECT + '/conditions/')\n",
    "\n",
    "if not os.path.exists(conditions_dir):\n",
    "    os.makedirs(conditions_dir)\n",
    "save_conditions(conditions_dir)\n",
    "\n",
    "# PPOTrainer()は、try_import_tfを使うと、なぜかTensorflowのeager modeのエラーになる。\n",
    "\n",
    "trainer = ppo.PPOTrainer(config=config,\n",
    "                         logger_creator=custom_log_creator(\n",
    "                             os.path.expanduser(\"./\" + PROJECT + \"/logs\"), TRIAL))\n",
    "\n",
    "if CONTINUAL:\n",
    "    # Continual learning: Need to specify the checkpoint\n",
    "    model_path = PROJECT + '/checkpoints/' + TRIAL + '/checkpoint_000001/checkpoint-1'\n",
    "    trainer.restore(checkpoint_path=model_path)\n",
    "\n",
    "models_dir = os.path.join('./' + PROJECT + '/models/')\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "text_name = models_dir + TRIAL + '.txt'\n",
    "with open(text_name, \"w\") as fp:\n",
    "    trainer.get_policy().model.base_model.summary(print_fn=lambda x: fp.write(x + \"\\r\\n\"))\n",
    "png_name = models_dir + TRIAL + '.png'\n",
    "plot_model(trainer.get_policy().model.base_model, to_file=png_name, show_shapes=True)\n",
    "\n",
    "# Instanciate the evaluation env\n",
    "eval_env = MyEnv({})\n",
    "\n",
    "# Define checkpoint dir\n",
    "check_point_dir = os.path.join('./' + PROJECT + '/checkpoints/', TRIAL)\n",
    "if not os.path.exists(check_point_dir):\n",
    "    os.makedirs(check_point_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b500596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def getkey(key):\n",
    "    # return 111\n",
    "#    return(bool(ctypes.windll.user32.GetAsyncKeyState(key) & 0x8000))\n",
    "# Training & evaluation\n",
    "\n",
    "record_mode = 1\n",
    "results_dir = os.path.join('./' + PROJECT + '/results/')\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "results_file = results_dir + TRIAL + '.pkl'\n",
    "for steps in range(10001):\n",
    "    # Training\n",
    "    # print(f'\\n----------------- Training at steps:{steps} start! -----------------')\n",
    "    # results = trainer.train()\n",
    "\n",
    "    # Evaluation\n",
    "    if steps % EVAL_FREQ == 0:\n",
    "        print(f'\\n----------------- Evaluation at steps:{steps} starting ! -----------------')\n",
    "        print(pretty_print(results))\n",
    "        check_point = trainer.save(checkpoint_dir=check_point_dir)\n",
    "        win = 0\n",
    "        for i in range(NUM_EVAL):\n",
    "            # print(f'\\nEvaluation {i}:')\n",
    "            obs = eval_env.reset()\n",
    "            done = False\n",
    "            \n",
    "            step_num = 0\n",
    "            fig = plt.figure(1)\n",
    "            ESC = 0x1B          # ESCキーの仮想キーコード\n",
    "            trajectory_length = 100\n",
    "            env_blue_pos = [0]\n",
    "            env_red_pos = [0]\n",
    "            env_mrm_pos = [0]\n",
    "            if record_mode == 0:\n",
    "                file_name = \"test_num\" + str(steps) +str(i)\n",
    "                video = cv2.VideoWriter(file_name+'.mp4',0x00000020,20.0,(eval_env.WINNDOW_SIZE_lon,eval_env.WINDOW_SIZE_lat))\n",
    "\n",
    "            while True:\n",
    "                action_dict = {}\n",
    "                for j in range(eval_env.blue_num):\n",
    "                    #if not eval_env.blue[j].hitpoint == 0:\n",
    "                    action_dict['blue_' + str(j)] = trainer.compute_action(obs['blue_' + str(j)])\n",
    "\n",
    "                obs, rewards, dones, infos = eval_env.step(action_dict)\n",
    "                env_blue_pos_temp, env_red_pos_temp, env_mrm_pos_temp= render_env.copy_from_env(eval_env)\n",
    "                env_blue_pos.append(env_blue_pos_temp)\n",
    "                env_red_pos.append(env_red_pos_temp)\n",
    "                env_mrm_pos.append(env_mrm_pos_temp)\n",
    "                if step_num == 0:\n",
    "                    del env_blue_pos[0]\n",
    "                    del env_red_pos[0]\n",
    "                    del env_mrm_pos[0]\n",
    "\n",
    "                hist_blue_pos = np.vstack(env_blue_pos)\n",
    "                hist_red_pos = np.vstack(env_red_pos)\n",
    "                hist_mrm_pos = np.vstack(env_mrm_pos)\n",
    "                plt.clf()\n",
    "                render_env.rend_3d(eval_env,hist_blue_pos,\"b\",1)\n",
    "                render_env.rend_3d(eval_env,hist_red_pos,\"r\",1)\n",
    "                render_env.rend_3d(eval_env,hist_mrm_pos,\"k\",1)\n",
    "                fig.canvas.draw()\n",
    "                plt.pause(.05)\n",
    "                if record_mode == 0:\n",
    "                    img = np.array(fig.canvas.renderer.buffer_rgba())\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_RGBA2BGR)\n",
    "                    # cv2.imshow('test', img)\n",
    "                    # cv2.waitKey(1)\n",
    "                    # cv2.destroyAllWindows()\n",
    "                    video.write(img.astype('uint8'))\n",
    "\n",
    "                \n",
    "                step_num = step_num + 1\n",
    "                \n",
    "                done = dones[\"__all__\"]\n",
    "                #print(f'rewards:{rewards}')\n",
    "                #if record_mode == 0:\n",
    "                #    img = eval_env.render_movie(file_name,step_num)\n",
    "                #    video.write(img.astype('unit8'))\n",
    "                #elif record_mode == 1:\n",
    "                #    eval_env.render()\n",
    "                #elif record_mode == 2:\n",
    "                #    eval_env.render()\n",
    "                    \n",
    "                #env_blue_pos_temp, env_red_pos_temp, env_mrm_pos_temp = render_env.copy_from_env(eval_env)\n",
    "                \n",
    "                #env_blue_pos.append(env_blue_pos_temp)\n",
    "                #env_red_pos.append(env_red_pos_temp)\n",
    "                #env_mrm_pos.append(env_mrm_pos_temp)\n",
    "                #step_num = step_num + 1\n",
    "                # エピソードの終了処理\n",
    "                if dones['__all__']:\n",
    "                    # print(f'all done at {env.steps}')\n",
    "                    break\n",
    "                \n",
    "            #del env_blue_pos[0]\n",
    "            #del env_red_pos[0]\n",
    "            #del env_mrm_pos[0]\n",
    "            \n",
    "            #hist_blue_pos = np.vstack(env_blue_pos)\n",
    "            #hist_red_pos = np.vstack(env_red_pos)\n",
    "            #hist_mrm_pos = np.vstack(env_mrm_pos)\n",
    "            \n",
    "            #f = open(results_file,'wb')\n",
    "            #pickle.dump(emv_blue_pos,f)\n",
    "            #pickle.dump(emv_red_pos,f)\n",
    "            #pickle.dump(emv_mrm_pos,f)\n",
    "            #f.close()\n",
    "            \n",
    "            if record_mode == 0:\n",
    "                video.release()\n",
    "\n",
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

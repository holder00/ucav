{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-06 08:30:03,617\tINFO services.py:1265 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2021-10-06 08:30:13,033\tINFO trainer.py:714 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "2021-10-06 08:30:13,034\tINFO ppo.py:159 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "2021-10-06 08:30:13,034\tINFO trainer.py:728 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m C:\\Users\\Takumi\\anaconda3\\envs\\AI_Ray\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "2021-10-06 08:30:19,679\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym.spaces import Discrete, Box\n",
    "\n",
    "import numpy as np\n",
    "from environment_rllib import MyEnv\n",
    "import ray\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "\n",
    "config = {\"env\": MyEnv,\"num_gpus\": 0,\"num_workers\": 1, \"num_cpus_per_worker\": 0}\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "trainer = PPOTrainer(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-06 08:30:55,703\tWARNING deprecation.py:39 -- DeprecationWarning: `slice` has been deprecated. Use `SampleBatch[start:stop]` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 4000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-30-57\n",
      "done: false\n",
      "episode_len_mean: 1002.0\n",
      "episode_media: {}\n",
      "episode_reward_max: -0.49803012034649086\n",
      "episode_reward_mean: -0.49803012034649086\n",
      "episode_reward_min: -0.49803012034649086\n",
      "episodes_this_iter: 1\n",
      "episodes_total: 1\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 2.0686452388763428\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011074709706008434\n",
      "        model: {}\n",
      "        policy_loss: -0.011886825785040855\n",
      "        total_loss: -0.009590217843651772\n",
      "        vf_explained_var: -0.1620893031358719\n",
      "        vf_loss: 8.167260966729373e-05\n",
      "  num_agent_steps_sampled: 4000\n",
      "  num_agent_steps_trained: 4000\n",
      "  num_steps_sampled: 4000\n",
      "  num_steps_trained: 4000\n",
      "iterations_since_restore: 1\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.76666666666667\n",
      "  ram_util_percent: 36.424074074074085\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.055078623713045824\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.70452107911346\n",
      "  mean_inference_ms: 1.1062437388254724\n",
      "  mean_raw_obs_processing_ms: 0.10716384914384848\n",
      "time_since_restore: 38.141730070114136\n",
      "time_this_iter_s: 38.141730070114136\n",
      "time_total_s: 38.141730070114136\n",
      "timers:\n",
      "  learn_throughput: 1882.989\n",
      "  learn_time_ms: 2124.282\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.083\n",
      "  sample_time_ms: 36009.141\n",
      "  update_time_ms: 1.995\n",
      "timestamp: 1633476657\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 4000\n",
      "training_iteration: 1\n",
      "\n",
      "agent_timesteps_total: 8000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-31-35\n",
      "done: false\n",
      "episode_len_mean: 1001.3333333333334\n",
      "episode_media: {}\n",
      "episode_reward_max: -0.40742037126894487\n",
      "episode_reward_mean: -0.45677100741687343\n",
      "episode_reward_min: -0.49803012034649086\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 3\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 2.0593247413635254\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009372281841933727\n",
      "        model: {}\n",
      "        policy_loss: -0.011522495187819004\n",
      "        total_loss: -0.009599835611879826\n",
      "        vf_explained_var: -0.005867761094123125\n",
      "        vf_loss: 4.8203059122897685e-05\n",
      "  num_agent_steps_sampled: 8000\n",
      "  num_agent_steps_trained: 8000\n",
      "  num_steps_sampled: 8000\n",
      "  num_steps_trained: 8000\n",
      "iterations_since_restore: 2\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.628301886792446\n",
      "  ram_util_percent: 36.45849056603774\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0564444611037034\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.70196375887026\n",
      "  mean_inference_ms: 1.097599686725775\n",
      "  mean_raw_obs_processing_ms: 0.11667109449950556\n",
      "time_since_restore: 75.9817533493042\n",
      "time_this_iter_s: 37.84002327919006\n",
      "time_total_s: 75.9817533493042\n",
      "timers:\n",
      "  learn_throughput: 2011.401\n",
      "  learn_time_ms: 1988.664\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.128\n",
      "  sample_time_ms: 35994.585\n",
      "  update_time_ms: 1.496\n",
      "timestamp: 1633476695\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 8000\n",
      "training_iteration: 2\n",
      "\n",
      "agent_timesteps_total: 12000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-32-13\n",
      "done: false\n",
      "episode_len_mean: 851.7142857142857\n",
      "episode_media: {}\n",
      "episode_reward_max: 0.8263890988944258\n",
      "episode_reward_mean: -0.24751057543297345\n",
      "episode_reward_min: -0.5706901407385166\n",
      "episodes_this_iter: 4\n",
      "episodes_total: 7\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 2.0519440174102783\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032087138388305902\n",
      "        model: {}\n",
      "        policy_loss: -0.007327057421207428\n",
      "        total_loss: -0.0033930090721696615\n",
      "        vf_explained_var: -0.6688953042030334\n",
      "        vf_loss: 0.003292301669716835\n",
      "  num_agent_steps_sampled: 12000\n",
      "  num_agent_steps_trained: 12000\n",
      "  num_steps_sampled: 12000\n",
      "  num_steps_trained: 12000\n",
      "iterations_since_restore: 3\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.970370370370368\n",
      "  ram_util_percent: 36.46666666666667\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.05791641373917154\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.71339069820764\n",
      "  mean_inference_ms: 1.0920307661975097\n",
      "  mean_raw_obs_processing_ms: 0.1233033256921068\n",
      "time_since_restore: 114.15902376174927\n",
      "time_this_iter_s: 38.17727041244507\n",
      "time_total_s: 114.15902376174927\n",
      "timers:\n",
      "  learn_throughput: 1996.334\n",
      "  learn_time_ms: 2003.672\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 110.989\n",
      "  sample_time_ms: 36039.622\n",
      "  update_time_ms: 1.33\n",
      "timestamp: 1633476733\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 12000\n",
      "training_iteration: 3\n",
      "\n",
      "agent_timesteps_total: 16000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-32-51\n",
      "done: false\n",
      "episode_len_mean: 884.8888888888889\n",
      "episode_media: {}\n",
      "episode_reward_max: 0.8263890988944258\n",
      "episode_reward_mean: -0.28332200039721317\n",
      "episode_reward_min: -0.5706901407385166\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 9\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 2.0370383262634277\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013165039010345936\n",
      "        model: {}\n",
      "        policy_loss: -0.01843101717531681\n",
      "        total_loss: -0.016459865495562553\n",
      "        vf_explained_var: -0.3237924575805664\n",
      "        vf_loss: 0.0006546459626406431\n",
      "  num_agent_steps_sampled: 16000\n",
      "  num_agent_steps_trained: 16000\n",
      "  num_steps_sampled: 16000\n",
      "  num_steps_trained: 16000\n",
      "iterations_since_restore: 4\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.89056603773585\n",
      "  ram_util_percent: 36.460377358490575\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.05830793893268203\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.712101533308665\n",
      "  mean_inference_ms: 1.0906409834772188\n",
      "  mean_raw_obs_processing_ms: 0.12407036656498846\n",
      "time_since_restore: 151.9199550151825\n",
      "time_this_iter_s: 37.76093125343323\n",
      "time_total_s: 151.9199550151825\n",
      "timers:\n",
      "  learn_throughput: 2033.248\n",
      "  learn_time_ms: 1967.296\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.101\n",
      "  sample_time_ms: 36003.415\n",
      "  update_time_ms: 1.247\n",
      "timestamp: 1633476771\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 16000\n",
      "training_iteration: 4\n",
      "\n",
      "agent_timesteps_total: 20000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-33-29\n",
      "done: false\n",
      "episode_len_mean: 830.25\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.08184504290311717\n",
      "episode_reward_min: -0.5706901407385166\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 12\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.9906879663467407\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008770361542701721\n",
      "        model: {}\n",
      "        policy_loss: -0.017783859744668007\n",
      "        total_loss: -0.011169932782649994\n",
      "        vf_explained_var: -0.5990321040153503\n",
      "        vf_loss: 0.00573689304292202\n",
      "  num_agent_steps_sampled: 20000\n",
      "  num_agent_steps_trained: 20000\n",
      "  num_steps_sampled: 20000\n",
      "  num_steps_trained: 20000\n",
      "iterations_since_restore: 5\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.82264150943396\n",
      "  ram_util_percent: 36.45660377358491\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.05859996786272039\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.712644568335737\n",
      "  mean_inference_ms: 1.0893684450190426\n",
      "  mean_raw_obs_processing_ms: 0.12458063419607217\n",
      "time_since_restore: 189.84274435043335\n",
      "time_this_iter_s: 37.922789335250854\n",
      "time_total_s: 189.84274435043335\n",
      "timers:\n",
      "  learn_throughput: 2054.847\n",
      "  learn_time_ms: 1946.617\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.071\n",
      "  sample_time_ms: 36013.083\n",
      "  update_time_ms: 1.396\n",
      "timestamp: 1633476809\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 20000\n",
      "training_iteration: 5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 24000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-34-07\n",
      "done: false\n",
      "episode_len_mean: 854.6428571428571\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.1332469584165287\n",
      "episode_reward_min: -0.5706901407385166\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 14\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.9897993803024292\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010995174758136272\n",
      "        model: {}\n",
      "        policy_loss: -0.018700648099184036\n",
      "        total_loss: -0.016389118507504463\n",
      "        vf_explained_var: -0.4145553708076477\n",
      "        vf_loss: 0.0012120085302740335\n",
      "  num_agent_steps_sampled: 24000\n",
      "  num_agent_steps_trained: 24000\n",
      "  num_steps_sampled: 24000\n",
      "  num_steps_trained: 24000\n",
      "iterations_since_restore: 6\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.345283018867928\n",
      "  ram_util_percent: 36.458490566037746\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.058971847883695375\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.71105439081467\n",
      "  mean_inference_ms: 1.088796258991853\n",
      "  mean_raw_obs_processing_ms: 0.12470305432739072\n",
      "time_since_restore: 227.58463668823242\n",
      "time_this_iter_s: 37.74189233779907\n",
      "time_total_s: 227.58463668823242\n",
      "timers:\n",
      "  learn_throughput: 2069.764\n",
      "  learn_time_ms: 1932.587\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.143\n",
      "  sample_time_ms: 35989.516\n",
      "  update_time_ms: 1.496\n",
      "timestamp: 1633476847\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 24000\n",
      "training_iteration: 6\n",
      "\n",
      "agent_timesteps_total: 28000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-34-45\n",
      "done: false\n",
      "episode_len_mean: 837.125\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.10572336814790992\n",
      "episode_reward_min: -0.5706901407385166\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 16\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.9908757209777832\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01212928257882595\n",
      "        model: {}\n",
      "        policy_loss: -0.012646076269447803\n",
      "        total_loss: -0.004962115082889795\n",
      "        vf_explained_var: -0.5315428376197815\n",
      "        vf_loss: 0.00647104112431407\n",
      "  num_agent_steps_sampled: 28000\n",
      "  num_agent_steps_trained: 28000\n",
      "  num_steps_sampled: 28000\n",
      "  num_steps_trained: 28000\n",
      "iterations_since_restore: 7\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 29.420370370370364\n",
      "  ram_util_percent: 36.464814814814815\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.059199976135777946\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.70897376448319\n",
      "  mean_inference_ms: 1.08841402935535\n",
      "  mean_raw_obs_processing_ms: 0.12467412830821234\n",
      "time_since_restore: 265.42852997779846\n",
      "time_this_iter_s: 37.84389328956604\n",
      "time_total_s: 265.42852997779846\n",
      "timers:\n",
      "  learn_throughput: 2064.503\n",
      "  learn_time_ms: 1937.513\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.197\n",
      "  sample_time_ms: 35972.317\n",
      "  update_time_ms: 1.425\n",
      "timestamp: 1633476885\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 28000\n",
      "training_iteration: 7\n",
      "\n",
      "agent_timesteps_total: 32000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-35-23\n",
      "done: false\n",
      "episode_len_mean: 855.3333333333334\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.14733824871328302\n",
      "episode_reward_min: -0.6386635883756931\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 18\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.8980077505111694\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01614864356815815\n",
      "        model: {}\n",
      "        policy_loss: -0.018437907099723816\n",
      "        total_loss: -0.016238970682024956\n",
      "        vf_explained_var: -0.49532589316368103\n",
      "        vf_loss: 0.000584068417083472\n",
      "  num_agent_steps_sampled: 32000\n",
      "  num_agent_steps_trained: 32000\n",
      "  num_steps_sampled: 32000\n",
      "  num_steps_trained: 32000\n",
      "iterations_since_restore: 8\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.5811320754717\n",
      "  ram_util_percent: 36.4433962264151\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.05946458029618535\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.70718231239537\n",
      "  mean_inference_ms: 1.0878499145787695\n",
      "  mean_raw_obs_processing_ms: 0.12465657080083029\n",
      "time_since_restore: 303.2106783390045\n",
      "time_this_iter_s: 37.782148361206055\n",
      "time_total_s: 303.2106783390045\n",
      "timers:\n",
      "  learn_throughput: 2075.586\n",
      "  learn_time_ms: 1927.166\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.217\n",
      "  sample_time_ms: 35965.776\n",
      "  update_time_ms: 1.496\n",
      "timestamp: 1633476923\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 32000\n",
      "training_iteration: 8\n",
      "\n",
      "agent_timesteps_total: 36000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-36-00\n",
      "done: false\n",
      "episode_len_mean: 869.9\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.1671111407912054\n",
      "episode_reward_min: -0.6386635883756931\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 20\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.9615153074264526\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01104405615478754\n",
      "        model: {}\n",
      "        policy_loss: -0.007714918814599514\n",
      "        total_loss: -0.006364772561937571\n",
      "        vf_explained_var: -0.573804497718811\n",
      "        vf_loss: 0.000245741248363629\n",
      "  num_agent_steps_sampled: 36000\n",
      "  num_agent_steps_trained: 36000\n",
      "  num_steps_sampled: 36000\n",
      "  num_steps_trained: 36000\n",
      "iterations_since_restore: 9\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.360377358490563\n",
      "  ram_util_percent: 36.46226415094339\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.05967723136659159\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.705813120321643\n",
      "  mean_inference_ms: 1.087285464467635\n",
      "  mean_raw_obs_processing_ms: 0.12452785336191452\n",
      "time_since_restore: 341.0385868549347\n",
      "time_this_iter_s: 37.827908515930176\n",
      "time_total_s: 341.0385868549347\n",
      "timers:\n",
      "  learn_throughput: 2080.426\n",
      "  learn_time_ms: 1922.683\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.228\n",
      "  sample_time_ms: 35962.19\n",
      "  update_time_ms: 1.552\n",
      "timestamp: 1633476960\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 36000\n",
      "training_iteration: 9\n",
      "\n",
      "agent_timesteps_total: 40000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-36-38\n",
      "done: false\n",
      "episode_len_mean: 856.8695652173913\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.21788233208892982\n",
      "episode_reward_min: -0.6386635883756931\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 23\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.96418297290802\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010239939205348492\n",
      "        model: {}\n",
      "        policy_loss: -0.004721181467175484\n",
      "        total_loss: -0.0034825578331947327\n",
      "        vf_explained_var: -0.31709182262420654\n",
      "        vf_loss: 0.0002146282058674842\n",
      "  num_agent_steps_sampled: 40000\n",
      "  num_agent_steps_trained: 40000\n",
      "  num_steps_sampled: 40000\n",
      "  num_steps_trained: 40000\n",
      "iterations_since_restore: 10\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.767924528301887\n",
      "  ram_util_percent: 36.58113207547169\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.05987727480379851\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.702276438179634\n",
      "  mean_inference_ms: 1.0865895385438145\n",
      "  mean_raw_obs_processing_ms: 0.12413700775912406\n",
      "time_since_restore: 378.5489583015442\n",
      "time_this_iter_s: 37.5103714466095\n",
      "time_total_s: 378.5489583015442\n",
      "timers:\n",
      "  learn_throughput: 2084.161\n",
      "  learn_time_ms: 1919.238\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.335\n",
      "  sample_time_ms: 35927.462\n",
      "  update_time_ms: 1.596\n",
      "timestamp: 1633476998\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 40000\n",
      "training_iteration: 10\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 44000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-37-16\n",
      "done: false\n",
      "episode_len_mean: 863.48\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.24072018326759242\n",
      "episode_reward_min: -0.6558783251420546\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 25\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.9069639444351196\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014312712475657463\n",
      "        model: {}\n",
      "        policy_loss: -0.015941614285111427\n",
      "        total_loss: -0.014348920434713364\n",
      "        vf_explained_var: -0.19026325643062592\n",
      "        vf_loss: 0.000161412957822904\n",
      "  num_agent_steps_sampled: 44000\n",
      "  num_agent_steps_trained: 44000\n",
      "  num_steps_sampled: 44000\n",
      "  num_steps_trained: 44000\n",
      "iterations_since_restore: 11\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.707547169811324\n",
      "  ram_util_percent: 36.5943396226415\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.05999650555498419\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.700434661517757\n",
      "  mean_inference_ms: 1.086102122029002\n",
      "  mean_raw_obs_processing_ms: 0.12388237760215504\n",
      "time_since_restore: 416.3577606678009\n",
      "time_this_iter_s: 37.808802366256714\n",
      "time_total_s: 416.3577606678009\n",
      "timers:\n",
      "  learn_throughput: 2108.399\n",
      "  learn_time_ms: 1897.174\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.37\n",
      "  sample_time_ms: 35916.205\n",
      "  update_time_ms: 1.596\n",
      "timestamp: 1633477036\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 44000\n",
      "training_iteration: 11\n",
      "\n",
      "agent_timesteps_total: 48000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-37-54\n",
      "done: false\n",
      "episode_len_mean: 859.7407407407408\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.2568087125547156\n",
      "episode_reward_min: -0.6558783251420546\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 27\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.8853529691696167\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01333729550242424\n",
      "        model: {}\n",
      "        policy_loss: -0.022173317149281502\n",
      "        total_loss: -0.02064601518213749\n",
      "        vf_explained_var: -0.19988872110843658\n",
      "        vf_loss: 0.00019357586279511452\n",
      "  num_agent_steps_sampled: 48000\n",
      "  num_agent_steps_trained: 48000\n",
      "  num_steps_sampled: 48000\n",
      "  num_steps_trained: 48000\n",
      "iterations_since_restore: 12\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.220754716981133\n",
      "  ram_util_percent: 36.5754716981132\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.060144751846672055\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.69924474089224\n",
      "  mean_inference_ms: 1.0856818665723103\n",
      "  mean_raw_obs_processing_ms: 0.12363915807182525\n",
      "time_since_restore: 454.3075489997864\n",
      "time_this_iter_s: 37.949788331985474\n",
      "time_total_s: 454.3075489997864\n",
      "timers:\n",
      "  learn_throughput: 2104.688\n",
      "  learn_time_ms: 1900.52\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.348\n",
      "  sample_time_ms: 35923.358\n",
      "  update_time_ms: 1.795\n",
      "timestamp: 1633477074\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 48000\n",
      "training_iteration: 12\n",
      "\n",
      "agent_timesteps_total: 52000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-38-31\n",
      "done: false\n",
      "episode_len_mean: 863.5666666666667\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.2679575014632282\n",
      "episode_reward_min: -0.6558783251420546\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 30\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.7684662342071533\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011859385296702385\n",
      "        model: {}\n",
      "        policy_loss: -0.013305654749274254\n",
      "        total_loss: -0.012007016688585281\n",
      "        vf_explained_var: -0.26679888367652893\n",
      "        vf_loss: 0.00011269964306848124\n",
      "  num_agent_steps_sampled: 52000\n",
      "  num_agent_steps_trained: 52000\n",
      "  num_steps_sampled: 52000\n",
      "  num_steps_trained: 52000\n",
      "iterations_since_restore: 13\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.760377358490565\n",
      "  ram_util_percent: 36.61132075471697\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06032740740948559\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.697804192321616\n",
      "  mean_inference_ms: 1.0851137760414598\n",
      "  mean_raw_obs_processing_ms: 0.12339475433737129\n",
      "time_since_restore: 492.11290740966797\n",
      "time_this_iter_s: 37.80535840988159\n",
      "time_total_s: 492.11290740966797\n",
      "timers:\n",
      "  learn_throughput: 2124.084\n",
      "  learn_time_ms: 1883.165\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.408\n",
      "  sample_time_ms: 35904.223\n",
      "  update_time_ms: 1.795\n",
      "timestamp: 1633477111\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 52000\n",
      "training_iteration: 13\n",
      "\n",
      "agent_timesteps_total: 56000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-39-09\n",
      "done: false\n",
      "episode_len_mean: 863.5625\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.285999571218896\n",
      "episode_reward_min: -0.6558783251420546\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 32\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.8783302307128906\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010643948800861835\n",
      "        model: {}\n",
      "        policy_loss: -0.007676355075091124\n",
      "        total_loss: -0.006543876137584448\n",
      "        vf_explained_var: -0.08601547032594681\n",
      "        vf_loss: 6.8081688368693e-05\n",
      "  num_agent_steps_sampled: 56000\n",
      "  num_agent_steps_trained: 56000\n",
      "  num_steps_sampled: 56000\n",
      "  num_steps_trained: 56000\n",
      "iterations_since_restore: 14\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.866037735849062\n",
      "  ram_util_percent: 36.58113207547169\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.060421610971464895\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.69671695978832\n",
      "  mean_inference_ms: 1.084779970163063\n",
      "  mean_raw_obs_processing_ms: 0.12325429745189681\n",
      "time_since_restore: 529.8738143444061\n",
      "time_this_iter_s: 37.76090693473816\n",
      "time_total_s: 529.8738143444061\n",
      "timers:\n",
      "  learn_throughput: 2113.321\n",
      "  learn_time_ms: 1892.756\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.437\n",
      "  sample_time_ms: 35894.652\n",
      "  update_time_ms: 1.795\n",
      "timestamp: 1633477149\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 56000\n",
      "training_iteration: 14\n",
      "\n",
      "agent_timesteps_total: 60000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-39-47\n",
      "done: false\n",
      "episode_len_mean: 868.9411764705883\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.30544726757086227\n",
      "episode_reward_min: -0.7552345969040674\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 34\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.8084102869033813\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010298672132194042\n",
      "        model: {}\n",
      "        policy_loss: -0.010290469974279404\n",
      "        total_loss: -0.009167368523776531\n",
      "        vf_explained_var: 0.010945330373942852\n",
      "        vf_loss: 9.323053382104263e-05\n",
      "  num_agent_steps_sampled: 60000\n",
      "  num_agent_steps_trained: 60000\n",
      "  num_steps_sampled: 60000\n",
      "  num_steps_trained: 60000\n",
      "iterations_since_restore: 15\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.1037037037037\n",
      "  ram_util_percent: 36.56851851851851\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06048683985668894\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.69541632785997\n",
      "  mean_inference_ms: 1.0844653780144151\n",
      "  mean_raw_obs_processing_ms: 0.12314507417838678\n",
      "time_since_restore: 567.6056654453278\n",
      "time_this_iter_s: 37.73185110092163\n",
      "time_total_s: 567.6056654453278\n",
      "timers:\n",
      "  learn_throughput: 2099.438\n",
      "  learn_time_ms: 1905.272\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.536\n",
      "  sample_time_ms: 35862.955\n",
      "  update_time_ms: 1.695\n",
      "timestamp: 1633477187\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 60000\n",
      "training_iteration: 15\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 64000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-40-25\n",
      "done: false\n",
      "episode_len_mean: 861.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.31746203705065373\n",
      "episode_reward_min: -0.7552345969040674\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 37\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.8465653657913208\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012973514385521412\n",
      "        model: {}\n",
      "        policy_loss: -0.0111669497564435\n",
      "        total_loss: -0.009716982021927834\n",
      "        vf_explained_var: -0.14677779376506805\n",
      "        vf_loss: 0.00015261085354723036\n",
      "  num_agent_steps_sampled: 64000\n",
      "  num_agent_steps_trained: 64000\n",
      "  num_steps_sampled: 64000\n",
      "  num_steps_trained: 64000\n",
      "iterations_since_restore: 16\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.126923076923074\n",
      "  ram_util_percent: 36.5576923076923\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.060571575730861436\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.693561298675647\n",
      "  mean_inference_ms: 1.084004126353961\n",
      "  mean_raw_obs_processing_ms: 0.12297789346163186\n",
      "time_since_restore: 605.292277097702\n",
      "time_this_iter_s: 37.68661165237427\n",
      "time_total_s: 605.292277097702\n",
      "timers:\n",
      "  learn_throughput: 2098.449\n",
      "  learn_time_ms: 1906.17\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.555\n",
      "  sample_time_ms: 35856.687\n",
      "  update_time_ms: 1.596\n",
      "timestamp: 1633477225\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 64000\n",
      "training_iteration: 16\n",
      "\n",
      "agent_timesteps_total: 68000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-41-02\n",
      "done: false\n",
      "episode_len_mean: 853.9230769230769\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.3181977177264389\n",
      "episode_reward_min: -0.7552345969040674\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 39\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.7796329259872437\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014668624848127365\n",
      "        model: {}\n",
      "        policy_loss: -0.018605712801218033\n",
      "        total_loss: -0.017032641917467117\n",
      "        vf_explained_var: 0.13821706175804138\n",
      "        vf_loss: 0.00010620453394949436\n",
      "  num_agent_steps_sampled: 68000\n",
      "  num_agent_steps_trained: 68000\n",
      "  num_steps_sampled: 68000\n",
      "  num_steps_trained: 68000\n",
      "iterations_since_restore: 17\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.586792452830192\n",
      "  ram_util_percent: 36.54528301886792\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06062413575925284\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.69234471772387\n",
      "  mean_inference_ms: 1.0837484454788884\n",
      "  mean_raw_obs_processing_ms: 0.1228628461791791\n",
      "time_since_restore: 642.9814865589142\n",
      "time_this_iter_s: 37.68920946121216\n",
      "time_total_s: 642.9814865589142\n",
      "timers:\n",
      "  learn_throughput: 2109.418\n",
      "  learn_time_ms: 1896.257\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.573\n",
      "  sample_time_ms: 35851.088\n",
      "  update_time_ms: 1.695\n",
      "timestamp: 1633477262\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 68000\n",
      "training_iteration: 17\n",
      "\n",
      "agent_timesteps_total: 72000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-41-40\n",
      "done: false\n",
      "episode_len_mean: 855.8571428571429\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.33304345201626007\n",
      "episode_reward_min: -0.7552345969040674\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 42\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.7144293785095215\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015756996348500252\n",
      "        model: {}\n",
      "        policy_loss: -0.01709792949259281\n",
      "        total_loss: -0.015395826660096645\n",
      "        vf_explained_var: -0.03652891889214516\n",
      "        vf_loss: 0.00012640022032428533\n",
      "  num_agent_steps_sampled: 72000\n",
      "  num_agent_steps_trained: 72000\n",
      "  num_steps_sampled: 72000\n",
      "  num_steps_trained: 72000\n",
      "iterations_since_restore: 18\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.052830188679245\n",
      "  ram_util_percent: 36.54339622641509\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0606854387296745\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.690401416828355\n",
      "  mean_inference_ms: 1.083355408985462\n",
      "  mean_raw_obs_processing_ms: 0.12269885948053838\n",
      "time_since_restore: 680.521594285965\n",
      "time_this_iter_s: 37.54010772705078\n",
      "time_total_s: 680.521594285965\n",
      "timers:\n",
      "  learn_throughput: 2110.219\n",
      "  learn_time_ms: 1895.538\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.646\n",
      "  sample_time_ms: 35827.634\n",
      "  update_time_ms: 1.695\n",
      "timestamp: 1633477300\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 72000\n",
      "training_iteration: 18\n",
      "\n",
      "agent_timesteps_total: 76000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-42-18\n",
      "done: false\n",
      "episode_len_mean: 856.2272727272727\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.34609511544625404\n",
      "episode_reward_min: -0.7966014117545593\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 44\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.732848048210144\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012350255623459816\n",
      "        model: {}\n",
      "        policy_loss: -0.01643109694123268\n",
      "        total_loss: -0.015095038339495659\n",
      "        vf_explained_var: 0.3012339472770691\n",
      "        vf_loss: 0.00010103229578817263\n",
      "  num_agent_steps_sampled: 76000\n",
      "  num_agent_steps_trained: 76000\n",
      "  num_steps_sampled: 76000\n",
      "  num_steps_trained: 76000\n",
      "iterations_since_restore: 19\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.256603773584906\n",
      "  ram_util_percent: 36.55849056603773\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06070978492868442\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.688948973492852\n",
      "  mean_inference_ms: 1.083122747069828\n",
      "  mean_raw_obs_processing_ms: 0.1225860611758192\n",
      "time_since_restore: 718.0177230834961\n",
      "time_this_iter_s: 37.49612879753113\n",
      "time_total_s: 718.0177230834961\n",
      "timers:\n",
      "  learn_throughput: 2110.984\n",
      "  learn_time_ms: 1894.851\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.747\n",
      "  sample_time_ms: 35795.171\n",
      "  update_time_ms: 1.695\n",
      "timestamp: 1633477338\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 76000\n",
      "training_iteration: 19\n",
      "\n",
      "agent_timesteps_total: 80000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-42-55\n",
      "done: false\n",
      "episode_len_mean: 854.6521739130435\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.35511591536776654\n",
      "episode_reward_min: -0.7966014117545593\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 46\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.7040276527404785\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01424985472112894\n",
      "        model: {}\n",
      "        policy_loss: -0.015432929620146751\n",
      "        total_loss: -0.013903831131756306\n",
      "        vf_explained_var: 0.1797253042459488\n",
      "        vf_loss: 0.00010411633411422372\n",
      "  num_agent_steps_sampled: 80000\n",
      "  num_agent_steps_trained: 80000\n",
      "  num_steps_sampled: 80000\n",
      "  num_steps_trained: 80000\n",
      "iterations_since_restore: 20\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.01320754716981\n",
      "  ram_util_percent: 36.54716981132075\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06073574252083554\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.687566634858772\n",
      "  mean_inference_ms: 1.082890169919383\n",
      "  mean_raw_obs_processing_ms: 0.12250136187116868\n",
      "time_since_restore: 755.7077298164368\n",
      "time_this_iter_s: 37.690006732940674\n",
      "time_total_s: 755.7077298164368\n",
      "timers:\n",
      "  learn_throughput: 2114.19\n",
      "  learn_time_ms: 1891.977\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.682\n",
      "  sample_time_ms: 35816.074\n",
      "  update_time_ms: 1.695\n",
      "timestamp: 1633477375\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 80000\n",
      "training_iteration: 20\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 84000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-43-33\n",
      "done: false\n",
      "episode_len_mean: 855.2448979591836\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.3723255286076965\n",
      "episode_reward_min: -0.7966014117545593\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 49\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.6224913597106934\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012287825345993042\n",
      "        model: {}\n",
      "        policy_loss: -0.013654911890625954\n",
      "        total_loss: -0.012345634400844574\n",
      "        vf_explained_var: -0.11027907580137253\n",
      "        vf_loss: 8.04934388725087e-05\n",
      "  num_agent_steps_sampled: 84000\n",
      "  num_agent_steps_trained: 84000\n",
      "  num_steps_sampled: 84000\n",
      "  num_steps_trained: 84000\n",
      "iterations_since_restore: 21\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.38490566037736\n",
      "  ram_util_percent: 36.55283018867924\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06075542555932408\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.68528951215525\n",
      "  mean_inference_ms: 1.0826011168779022\n",
      "  mean_raw_obs_processing_ms: 0.1223773430949698\n",
      "time_since_restore: 793.2288041114807\n",
      "time_this_iter_s: 37.521074295043945\n",
      "time_total_s: 793.2288041114807\n",
      "timers:\n",
      "  learn_throughput: 2111.64\n",
      "  learn_time_ms: 1894.262\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.779\n",
      "  sample_time_ms: 35785.047\n",
      "  update_time_ms: 1.652\n",
      "timestamp: 1633477413\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 84000\n",
      "training_iteration: 21\n",
      "\n",
      "agent_timesteps_total: 88000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-44-11\n",
      "done: false\n",
      "episode_len_mean: 855.4509803921569\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.3789297213454432\n",
      "episode_reward_min: -0.7966014117545593\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 51\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.5657732486724854\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01032545417547226\n",
      "        model: {}\n",
      "        policy_loss: -0.007608712185174227\n",
      "        total_loss: -0.006483078468590975\n",
      "        vf_explained_var: -0.03936474025249481\n",
      "        vf_loss: 9.308948938269168e-05\n",
      "  num_agent_steps_sampled: 88000\n",
      "  num_agent_steps_trained: 88000\n",
      "  num_steps_sampled: 88000\n",
      "  num_steps_trained: 88000\n",
      "iterations_since_restore: 22\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.86603773584906\n",
      "  ram_util_percent: 36.55094339622641\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06078130280004266\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.683910647723266\n",
      "  mean_inference_ms: 1.0824325043048788\n",
      "  mean_raw_obs_processing_ms: 0.12232067075836113\n",
      "time_since_restore: 831.0072510242462\n",
      "time_this_iter_s: 37.7784469127655\n",
      "time_total_s: 831.0072510242462\n",
      "timers:\n",
      "  learn_throughput: 2112.298\n",
      "  learn_time_ms: 1893.672\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.828\n",
      "  sample_time_ms: 35769.059\n",
      "  update_time_ms: 1.553\n",
      "timestamp: 1633477451\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 88000\n",
      "training_iteration: 22\n",
      "\n",
      "agent_timesteps_total: 92000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-44-48\n",
      "done: false\n",
      "episode_len_mean: 855.3396226415094\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.3858619779761445\n",
      "episode_reward_min: -0.7966014117545593\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 53\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.644439935684204\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012218393385410309\n",
      "        model: {}\n",
      "        policy_loss: -0.015167034231126308\n",
      "        total_loss: -0.013841342180967331\n",
      "        vf_explained_var: 0.43890491127967834\n",
      "        vf_loss: 0.00010385592031525448\n",
      "  num_agent_steps_sampled: 92000\n",
      "  num_agent_steps_trained: 92000\n",
      "  num_steps_sampled: 92000\n",
      "  num_steps_trained: 92000\n",
      "iterations_since_restore: 23\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 28.60754716981132\n",
      "  ram_util_percent: 36.573584905660375\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.060786214631870124\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.682594252947673\n",
      "  mean_inference_ms: 1.0822766374403705\n",
      "  mean_raw_obs_processing_ms: 0.12228927007751236\n",
      "time_since_restore: 868.8635563850403\n",
      "time_this_iter_s: 37.85630536079407\n",
      "time_total_s: 868.8635563850403\n",
      "timers:\n",
      "  learn_throughput: 2092.396\n",
      "  learn_time_ms: 1911.684\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.869\n",
      "  sample_time_ms: 35756.039\n",
      "  update_time_ms: 1.652\n",
      "timestamp: 1633477488\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 92000\n",
      "training_iteration: 23\n",
      "\n",
      "agent_timesteps_total: 96000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-45-26\n",
      "done: false\n",
      "episode_len_mean: 856.7678571428571\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.3982608489951966\n",
      "episode_reward_min: -0.7966014117545593\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 56\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.59319007396698\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012504502199590206\n",
      "        model: {}\n",
      "        policy_loss: -0.01327267475426197\n",
      "        total_loss: -0.011922513134777546\n",
      "        vf_explained_var: 0.08192388713359833\n",
      "        vf_loss: 9.971229155780748e-05\n",
      "  num_agent_steps_sampled: 96000\n",
      "  num_agent_steps_trained: 96000\n",
      "  num_steps_sampled: 96000\n",
      "  num_steps_trained: 96000\n",
      "iterations_since_restore: 24\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.894339622641503\n",
      "  ram_util_percent: 36.56603773584905\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0607733883551767\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.68061170259396\n",
      "  mean_inference_ms: 1.0820686791943204\n",
      "  mean_raw_obs_processing_ms: 0.12226097631514962\n",
      "time_since_restore: 906.4360661506653\n",
      "time_this_iter_s: 37.572509765625\n",
      "time_total_s: 906.4360661506653\n",
      "timers:\n",
      "  learn_throughput: 2101.314\n",
      "  learn_time_ms: 1903.57\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.902\n",
      "  sample_time_ms: 35745.418\n",
      "  update_time_ms: 1.653\n",
      "timestamp: 1633477526\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 96000\n",
      "training_iteration: 24\n",
      "\n",
      "agent_timesteps_total: 100000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-46-04\n",
      "done: false\n",
      "episode_len_mean: 856.0689655172414\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.407034031369445\n",
      "episode_reward_min: -0.8106209692443905\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 58\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.648711085319519\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012478623539209366\n",
      "        model: {}\n",
      "        policy_loss: -0.018885213881731033\n",
      "        total_loss: -0.01756764017045498\n",
      "        vf_explained_var: -0.059080321341753006\n",
      "        vf_loss: 6.971508264541626e-05\n",
      "  num_agent_steps_sampled: 100000\n",
      "  num_agent_steps_trained: 100000\n",
      "  num_steps_sampled: 100000\n",
      "  num_steps_trained: 100000\n",
      "iterations_since_restore: 25\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.209433962264153\n",
      "  ram_util_percent: 36.58490566037735\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0607604797771727\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.679299202521204\n",
      "  mean_inference_ms: 1.0819389266712374\n",
      "  mean_raw_obs_processing_ms: 0.12224316386033172\n",
      "time_since_restore: 944.021603345871\n",
      "time_this_iter_s: 37.58553719520569\n",
      "time_total_s: 944.021603345871\n",
      "timers:\n",
      "  learn_throughput: 2112.246\n",
      "  learn_time_ms: 1893.719\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.917\n",
      "  sample_time_ms: 35740.622\n",
      "  update_time_ms: 1.734\n",
      "timestamp: 1633477564\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 100000\n",
      "training_iteration: 25\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 104000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-46-41\n",
      "done: false\n",
      "episode_len_mean: 860.9\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.41765441171201834\n",
      "episode_reward_min: -0.8106209692443905\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 60\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.5588791370391846\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013825668953359127\n",
      "        model: {}\n",
      "        policy_loss: -0.014593691565096378\n",
      "        total_loss: -0.013157114386558533\n",
      "        vf_explained_var: 0.22506362199783325\n",
      "        vf_loss: 5.40144246770069e-05\n",
      "  num_agent_steps_sampled: 104000\n",
      "  num_agent_steps_trained: 104000\n",
      "  num_steps_sampled: 104000\n",
      "  num_steps_trained: 104000\n",
      "iterations_since_restore: 26\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.89433962264151\n",
      "  ram_util_percent: 36.54150943396226\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06073853058048808\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.678051523725014\n",
      "  mean_inference_ms: 1.0818090826028213\n",
      "  mean_raw_obs_processing_ms: 0.12222527833822629\n",
      "time_since_restore: 981.6914849281311\n",
      "time_this_iter_s: 37.66988158226013\n",
      "time_total_s: 981.6914849281311\n",
      "timers:\n",
      "  learn_throughput: 2111.102\n",
      "  learn_time_ms: 1894.745\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.926\n",
      "  sample_time_ms: 35737.879\n",
      "  update_time_ms: 1.833\n",
      "timestamp: 1633477601\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 104000\n",
      "training_iteration: 26\n",
      "\n",
      "agent_timesteps_total: 108000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-47-19\n",
      "done: false\n",
      "episode_len_mean: 856.258064516129\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.40670128591225535\n",
      "episode_reward_min: -0.8106209692443905\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 62\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.541036605834961\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008191760629415512\n",
      "        model: {}\n",
      "        policy_loss: -0.013991023413836956\n",
      "        total_loss: -0.007600641343742609\n",
      "        vf_explained_var: -0.6530126333236694\n",
      "        vf_loss: 0.0055712065659463406\n",
      "  num_agent_steps_sampled: 108000\n",
      "  num_agent_steps_trained: 108000\n",
      "  num_steps_sampled: 108000\n",
      "  num_steps_trained: 108000\n",
      "iterations_since_restore: 27\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.545283018867924\n",
      "  ram_util_percent: 36.54150943396226\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06072113883814518\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.67682905102583\n",
      "  mean_inference_ms: 1.0816717712541954\n",
      "  mean_raw_obs_processing_ms: 0.12221474136688083\n",
      "time_since_restore: 1019.4067840576172\n",
      "time_this_iter_s: 37.715299129486084\n",
      "time_total_s: 1019.4067840576172\n",
      "timers:\n",
      "  learn_throughput: 2099.881\n",
      "  learn_time_ms: 1904.87\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.949\n",
      "  sample_time_ms: 35730.464\n",
      "  update_time_ms: 1.834\n",
      "timestamp: 1633477639\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 108000\n",
      "training_iteration: 27\n",
      "\n",
      "agent_timesteps_total: 112000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-47-57\n",
      "done: false\n",
      "episode_len_mean: 860.723076923077\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.41447704481027436\n",
      "episode_reward_min: -0.8106209692443905\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 65\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4518722295761108\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012532803229987621\n",
      "        model: {}\n",
      "        policy_loss: -0.014466867782175541\n",
      "        total_loss: -0.01227939035743475\n",
      "        vf_explained_var: -0.42608967423439026\n",
      "        vf_loss: 0.0009342000121250749\n",
      "  num_agent_steps_sampled: 112000\n",
      "  num_agent_steps_trained: 112000\n",
      "  num_steps_sampled: 112000\n",
      "  num_steps_trained: 112000\n",
      "iterations_since_restore: 28\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.1377358490566\n",
      "  ram_util_percent: 36.55849056603773\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06068664311172524\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.675100487930095\n",
      "  mean_inference_ms: 1.0814771656051763\n",
      "  mean_raw_obs_processing_ms: 0.12219642324669756\n",
      "time_since_restore: 1057.1473145484924\n",
      "time_this_iter_s: 37.740530490875244\n",
      "time_total_s: 1057.1473145484924\n",
      "timers:\n",
      "  learn_throughput: 2087.675\n",
      "  learn_time_ms: 1916.007\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.922\n",
      "  sample_time_ms: 35739.281\n",
      "  update_time_ms: 1.833\n",
      "timestamp: 1633477677\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 112000\n",
      "training_iteration: 28\n",
      "\n",
      "agent_timesteps_total: 116000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-48-34\n",
      "done: false\n",
      "episode_len_mean: 864.9104477611941\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.4228430915229987\n",
      "episode_reward_min: -0.8106209692443905\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 67\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.5526587963104248\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014744583517313004\n",
      "        model: {}\n",
      "        policy_loss: -0.01257555652409792\n",
      "        total_loss: -0.010886168107390404\n",
      "        vf_explained_var: -0.12199432402849197\n",
      "        vf_loss: 0.00021493448002729565\n",
      "  num_agent_steps_sampled: 116000\n",
      "  num_agent_steps_trained: 116000\n",
      "  num_steps_sampled: 116000\n",
      "  num_steps_trained: 116000\n",
      "iterations_since_restore: 29\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.49245283018868\n",
      "  ram_util_percent: 36.55094339622641\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.060662912114047784\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.673992372242306\n",
      "  mean_inference_ms: 1.0813441861453768\n",
      "  mean_raw_obs_processing_ms: 0.12218553821586076\n",
      "time_since_restore: 1094.7502505779266\n",
      "time_this_iter_s: 37.602936029434204\n",
      "time_total_s: 1094.7502505779266\n",
      "timers:\n",
      "  learn_throughput: 2088.766\n",
      "  learn_time_ms: 1915.006\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.885\n",
      "  sample_time_ms: 35750.901\n",
      "  update_time_ms: 1.834\n",
      "timestamp: 1633477714\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 116000\n",
      "training_iteration: 29\n",
      "\n",
      "agent_timesteps_total: 120000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-49-12\n",
      "done: false\n",
      "episode_len_mean: 868.8550724637681\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.42409935865888765\n",
      "episode_reward_min: -0.8106209692443905\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 69\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.5660927295684814\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007733957376331091\n",
      "        model: {}\n",
      "        policy_loss: -0.009750958532094955\n",
      "        total_loss: -0.008826097473502159\n",
      "        vf_explained_var: 0.03265663981437683\n",
      "        vf_loss: 0.00015146555961109698\n",
      "  num_agent_steps_sampled: 120000\n",
      "  num_agent_steps_trained: 120000\n",
      "  num_steps_sampled: 120000\n",
      "  num_steps_trained: 120000\n",
      "iterations_since_restore: 30\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.918867924528307\n",
      "  ram_util_percent: 36.54150943396226\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06064576882147139\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.672959484965205\n",
      "  mean_inference_ms: 1.0812043635571555\n",
      "  mean_raw_obs_processing_ms: 0.122170324831979\n",
      "time_since_restore: 1132.4398550987244\n",
      "time_this_iter_s: 37.68960452079773\n",
      "time_total_s: 1132.4398550987244\n",
      "timers:\n",
      "  learn_throughput: 2089.514\n",
      "  learn_time_ms: 1914.321\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.883\n",
      "  sample_time_ms: 35751.515\n",
      "  update_time_ms: 1.833\n",
      "timestamp: 1633477752\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 120000\n",
      "training_iteration: 30\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 124000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-49-50\n",
      "done: false\n",
      "episode_len_mean: 867.6619718309859\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.4316472780583162\n",
      "episode_reward_min: -0.8106209692443905\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 71\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.484955906867981\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012226232327520847\n",
      "        model: {}\n",
      "        policy_loss: -0.006542233284562826\n",
      "        total_loss: -0.005194406490772963\n",
      "        vf_explained_var: -0.28916606307029724\n",
      "        vf_loss: 0.00012520111340563744\n",
      "  num_agent_steps_sampled: 124000\n",
      "  num_agent_steps_trained: 124000\n",
      "  num_steps_sampled: 124000\n",
      "  num_steps_trained: 124000\n",
      "iterations_since_restore: 31\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.415094339622637\n",
      "  ram_util_percent: 36.53584905660377\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06063999721419205\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.67190320106821\n",
      "  mean_inference_ms: 1.0810710896466347\n",
      "  mean_raw_obs_processing_ms: 0.12216072754911002\n",
      "time_since_restore: 1170.0667552947998\n",
      "time_this_iter_s: 37.62690019607544\n",
      "time_total_s: 1170.0667552947998\n",
      "timers:\n",
      "  learn_throughput: 2088.481\n",
      "  learn_time_ms: 1915.268\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.853\n",
      "  sample_time_ms: 35761.304\n",
      "  update_time_ms: 1.777\n",
      "timestamp: 1633477790\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 124000\n",
      "training_iteration: 31\n",
      "\n",
      "agent_timesteps_total: 128000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-50-27\n",
      "done: false\n",
      "episode_len_mean: 871.3150684931506\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.43447457798972344\n",
      "episode_reward_min: -0.8106209692443905\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 73\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.3413002490997314\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00931000616401434\n",
      "        model: {}\n",
      "        policy_loss: -0.014790995046496391\n",
      "        total_loss: -0.013772725127637386\n",
      "        vf_explained_var: 0.26069629192352295\n",
      "        vf_loss: 8.726806117920205e-05\n",
      "  num_agent_steps_sampled: 128000\n",
      "  num_agent_steps_trained: 128000\n",
      "  num_steps_sampled: 128000\n",
      "  num_steps_trained: 128000\n",
      "iterations_since_restore: 32\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 24.23461538461538\n",
      "  ram_util_percent: 36.53076923076923\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06063023316179384\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.670853224787326\n",
      "  mean_inference_ms: 1.0809359334030901\n",
      "  mean_raw_obs_processing_ms: 0.12215537372881287\n",
      "time_since_restore: 1207.6055796146393\n",
      "time_this_iter_s: 37.53882431983948\n",
      "time_total_s: 1207.6055796146393\n",
      "timers:\n",
      "  learn_throughput: 2091.604\n",
      "  learn_time_ms: 1912.408\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.919\n",
      "  sample_time_ms: 35740.117\n",
      "  update_time_ms: 1.777\n",
      "timestamp: 1633477827\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 128000\n",
      "training_iteration: 32\n",
      "\n",
      "agent_timesteps_total: 132000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-51-05\n",
      "done: false\n",
      "episode_len_mean: 874.7733333333333\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.442390731720038\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 75\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.462854266166687\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011614840477705002\n",
      "        model: {}\n",
      "        policy_loss: -0.007571033667773008\n",
      "        total_loss: -0.006331693381071091\n",
      "        vf_explained_var: -0.09830193221569061\n",
      "        vf_loss: 7.785103662172332e-05\n",
      "  num_agent_steps_sampled: 132000\n",
      "  num_agent_steps_trained: 132000\n",
      "  num_steps_sampled: 132000\n",
      "  num_steps_trained: 132000\n",
      "iterations_since_restore: 33\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.098113207547172\n",
      "  ram_util_percent: 36.54528301886792\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06061691218581237\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.66985648409109\n",
      "  mean_inference_ms: 1.0808043337568636\n",
      "  mean_raw_obs_processing_ms: 0.12215270219501387\n",
      "time_since_restore: 1245.2869102954865\n",
      "time_this_iter_s: 37.68133068084717\n",
      "time_total_s: 1245.2869102954865\n",
      "timers:\n",
      "  learn_throughput: 2110.107\n",
      "  learn_time_ms: 1895.639\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.921\n",
      "  sample_time_ms: 35739.51\n",
      "  update_time_ms: 1.677\n",
      "timestamp: 1633477865\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 132000\n",
      "training_iteration: 33\n",
      "\n",
      "agent_timesteps_total: 136000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-51-43\n",
      "done: false\n",
      "episode_len_mean: 878.0519480519481\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.4485201751191293\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 77\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.426049828529358\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.017786744982004166\n",
      "        model: {}\n",
      "        policy_loss: -0.01974862441420555\n",
      "        total_loss: -0.01790878176689148\n",
      "        vf_explained_var: -0.04526287689805031\n",
      "        vf_loss: 6.116869917605072e-05\n",
      "  num_agent_steps_sampled: 136000\n",
      "  num_agent_steps_trained: 136000\n",
      "  num_steps_sampled: 136000\n",
      "  num_steps_trained: 136000\n",
      "iterations_since_restore: 34\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.115094339622644\n",
      "  ram_util_percent: 36.526415094339626\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06060901190998892\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.668857280042523\n",
      "  mean_inference_ms: 1.0806697439710968\n",
      "  mean_raw_obs_processing_ms: 0.1221588651125805\n",
      "time_since_restore: 1282.8504478931427\n",
      "time_this_iter_s: 37.56353759765625\n",
      "time_total_s: 1282.8504478931427\n",
      "timers:\n",
      "  learn_throughput: 2110.393\n",
      "  learn_time_ms: 1895.381\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.923\n",
      "  sample_time_ms: 35738.846\n",
      "  update_time_ms: 1.677\n",
      "timestamp: 1633477903\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 136000\n",
      "training_iteration: 34\n",
      "\n",
      "agent_timesteps_total: 140000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-52-20\n",
      "done: false\n",
      "episode_len_mean: 878.0379746835443\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.45451501134456096\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 79\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.3111889362335205\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01001645065844059\n",
      "        model: {}\n",
      "        policy_loss: -0.0074987574480473995\n",
      "        total_loss: -0.006392861250787973\n",
      "        vf_explained_var: 0.10058359056711197\n",
      "        vf_loss: 0.00010425357322674245\n",
      "  num_agent_steps_sampled: 140000\n",
      "  num_agent_steps_trained: 140000\n",
      "  num_steps_sampled: 140000\n",
      "  num_steps_trained: 140000\n",
      "iterations_since_restore: 35\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.200000000000003\n",
      "  ram_util_percent: 36.52075471698113\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06060536431400099\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.66782566519227\n",
      "  mean_inference_ms: 1.080542283361366\n",
      "  mean_raw_obs_processing_ms: 0.12216819335138734\n",
      "time_since_restore: 1320.4020507335663\n",
      "time_this_iter_s: 37.551602840423584\n",
      "time_total_s: 1320.4020507335663\n",
      "timers:\n",
      "  learn_throughput: 2105.965\n",
      "  learn_time_ms: 1899.366\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.946\n",
      "  sample_time_ms: 35731.386\n",
      "  update_time_ms: 1.695\n",
      "timestamp: 1633477940\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 140000\n",
      "training_iteration: 35\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 144000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-52-58\n",
      "done: false\n",
      "episode_len_mean: 878.6172839506173\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.4562417866008813\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 81\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.298803687095642\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011470821686089039\n",
      "        model: {}\n",
      "        policy_loss: -0.01932106912136078\n",
      "        total_loss: -0.0180734284222126\n",
      "        vf_explained_var: 0.05962418019771576\n",
      "        vf_loss: 0.00010056095925392583\n",
      "  num_agent_steps_sampled: 144000\n",
      "  num_agent_steps_trained: 144000\n",
      "  num_steps_sampled: 144000\n",
      "  num_steps_trained: 144000\n",
      "iterations_since_restore: 36\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.01320754716981\n",
      "  ram_util_percent: 36.528301886792455\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06060136992793055\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.66681902256114\n",
      "  mean_inference_ms: 1.0804207213150283\n",
      "  mean_raw_obs_processing_ms: 0.12216880873112705\n",
      "time_since_restore: 1357.972490787506\n",
      "time_this_iter_s: 37.57044005393982\n",
      "time_total_s: 1357.972490787506\n",
      "timers:\n",
      "  learn_throughput: 2108.62\n",
      "  learn_time_ms: 1896.975\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.97\n",
      "  sample_time_ms: 35723.889\n",
      "  update_time_ms: 1.695\n",
      "timestamp: 1633477978\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 144000\n",
      "training_iteration: 36\n",
      "\n",
      "agent_timesteps_total: 148000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-53-35\n",
      "done: false\n",
      "episode_len_mean: 878.0357142857143\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.45847267820396065\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 84\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.2462815046310425\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012586423195898533\n",
      "        model: {}\n",
      "        policy_loss: -0.01562889851629734\n",
      "        total_loss: -0.01430536899715662\n",
      "        vf_explained_var: 0.15061897039413452\n",
      "        vf_loss: 6.488321378128603e-05\n",
      "  num_agent_steps_sampled: 148000\n",
      "  num_agent_steps_trained: 148000\n",
      "  num_steps_sampled: 148000\n",
      "  num_steps_trained: 148000\n",
      "iterations_since_restore: 37\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 28.035849056603777\n",
      "  ram_util_percent: 36.549056603773586\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.060594924286551034\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.665393451872866\n",
      "  mean_inference_ms: 1.0802400072906266\n",
      "  mean_raw_obs_processing_ms: 0.1221668883454544\n",
      "time_since_restore: 1395.6156113147736\n",
      "time_this_iter_s: 37.643120527267456\n",
      "time_total_s: 1395.6156113147736\n",
      "timers:\n",
      "  learn_throughput: 2120.353\n",
      "  learn_time_ms: 1886.479\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.96\n",
      "  sample_time_ms: 35727.162\n",
      "  update_time_ms: 1.696\n",
      "timestamp: 1633478015\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 148000\n",
      "training_iteration: 37\n",
      "\n",
      "agent_timesteps_total: 152000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-54-13\n",
      "done: false\n",
      "episode_len_mean: 880.8953488372093\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.46139329676755364\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 86\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.2599073648452759\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009890790097415447\n",
      "        model: {}\n",
      "        policy_loss: -0.009371272288262844\n",
      "        total_loss: -0.008342085406184196\n",
      "        vf_explained_var: 0.2048960030078888\n",
      "        vf_loss: 4.0109280234901235e-05\n",
      "  num_agent_steps_sampled: 152000\n",
      "  num_agent_steps_trained: 152000\n",
      "  num_steps_sampled: 152000\n",
      "  num_steps_trained: 152000\n",
      "iterations_since_restore: 38\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.50566037735849\n",
      "  ram_util_percent: 36.54528301886792\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06059202677396839\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.66449300362877\n",
      "  mean_inference_ms: 1.0801333002132913\n",
      "  mean_raw_obs_processing_ms: 0.1221626345406653\n",
      "time_since_restore: 1433.296575307846\n",
      "time_this_iter_s: 37.68096399307251\n",
      "time_total_s: 1433.296575307846\n",
      "timers:\n",
      "  learn_throughput: 2130.143\n",
      "  learn_time_ms: 1877.808\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.951\n",
      "  sample_time_ms: 35729.89\n",
      "  update_time_ms: 1.715\n",
      "timestamp: 1633478053\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 152000\n",
      "training_iteration: 38\n",
      "\n",
      "agent_timesteps_total: 156000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-54-51\n",
      "done: false\n",
      "episode_len_mean: 880.5\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.46578311402037914\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 88\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.2323882579803467\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009913751855492592\n",
      "        model: {}\n",
      "        policy_loss: -0.009281259030103683\n",
      "        total_loss: -0.008211185224354267\n",
      "        vf_explained_var: 0.10012013465166092\n",
      "        vf_loss: 7.869810360716656e-05\n",
      "  num_agent_steps_sampled: 156000\n",
      "  num_agent_steps_trained: 156000\n",
      "  num_steps_sampled: 156000\n",
      "  num_steps_trained: 156000\n",
      "iterations_since_restore: 39\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 28.720754716981133\n",
      "  ram_util_percent: 36.583018867924515\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.060587391161892844\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.66364773816542\n",
      "  mean_inference_ms: 1.0800335880412733\n",
      "  mean_raw_obs_processing_ms: 0.12215916243607315\n",
      "time_since_restore: 1471.0522882938385\n",
      "time_this_iter_s: 37.75571298599243\n",
      "time_total_s: 1471.0522882938385\n",
      "timers:\n",
      "  learn_throughput: 2128.551\n",
      "  learn_time_ms: 1879.213\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.907\n",
      "  sample_time_ms: 35743.832\n",
      "  update_time_ms: 1.616\n",
      "timestamp: 1633478091\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 156000\n",
      "training_iteration: 39\n",
      "\n",
      "agent_timesteps_total: 160000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-55-28\n",
      "done: false\n",
      "episode_len_mean: 873.2637362637363\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.4622731824366895\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 91\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.1762984991073608\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008695563301444054\n",
      "        model: {}\n",
      "        policy_loss: -0.01329128723591566\n",
      "        total_loss: -0.012379314750432968\n",
      "        vf_explained_var: 0.047773152589797974\n",
      "        vf_loss: 4.241334318066947e-05\n",
      "  num_agent_steps_sampled: 160000\n",
      "  num_agent_steps_trained: 160000\n",
      "  num_steps_sampled: 160000\n",
      "  num_steps_trained: 160000\n",
      "iterations_since_restore: 40\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.728846153846156\n",
      "  ram_util_percent: 36.590384615384615\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06057944395551085\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.662384902407393\n",
      "  mean_inference_ms: 1.079892388610228\n",
      "  mean_raw_obs_processing_ms: 0.1221501982259578\n",
      "time_since_restore: 1508.548909187317\n",
      "time_this_iter_s: 37.496620893478394\n",
      "time_total_s: 1508.548909187317\n",
      "timers:\n",
      "  learn_throughput: 2128.913\n",
      "  learn_time_ms: 1878.893\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.967\n",
      "  sample_time_ms: 35724.817\n",
      "  update_time_ms: 1.616\n",
      "timestamp: 1633478128\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 160000\n",
      "training_iteration: 40\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 164000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-56-06\n",
      "done: false\n",
      "episode_len_mean: 873.5806451612904\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.4652771414203921\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 93\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.1862568855285645\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015253475867211819\n",
      "        model: {}\n",
      "        policy_loss: -0.01840311661362648\n",
      "        total_loss: -0.01678980514407158\n",
      "        vf_explained_var: 0.31137195229530334\n",
      "        vf_loss: 8.796664769761264e-05\n",
      "  num_agent_steps_sampled: 164000\n",
      "  num_agent_steps_trained: 164000\n",
      "  num_steps_sampled: 164000\n",
      "  num_steps_trained: 164000\n",
      "iterations_since_restore: 41\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.766037735849054\n",
      "  ram_util_percent: 36.59999999999999\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06057026231821252\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.66156259024545\n",
      "  mean_inference_ms: 1.0798019509408474\n",
      "  mean_raw_obs_processing_ms: 0.12214310342659768\n",
      "time_since_restore: 1546.093684911728\n",
      "time_this_iter_s: 37.54477572441101\n",
      "time_total_s: 1546.093684911728\n",
      "timers:\n",
      "  learn_throughput: 2137.317\n",
      "  learn_time_ms: 1871.505\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.97\n",
      "  sample_time_ms: 35723.901\n",
      "  update_time_ms: 1.73\n",
      "timestamp: 1633478166\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 164000\n",
      "training_iteration: 41\n",
      "\n",
      "agent_timesteps_total: 168000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-56-43\n",
      "done: false\n",
      "episode_len_mean: 872.34375\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.46994589685250254\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 96\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.1156625747680664\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009474395774304867\n",
      "        model: {}\n",
      "        policy_loss: -0.010748383589088917\n",
      "        total_loss: -0.009744701907038689\n",
      "        vf_explained_var: 0.3291957974433899\n",
      "        vf_loss: 5.624457844533026e-05\n",
      "  num_agent_steps_sampled: 168000\n",
      "  num_agent_steps_trained: 168000\n",
      "  num_steps_sampled: 168000\n",
      "  num_steps_trained: 168000\n",
      "iterations_since_restore: 42\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.34905660377358\n",
      "  ram_util_percent: 36.59056603773584\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06055828246775457\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.660325736514064\n",
      "  mean_inference_ms: 1.0796736623444834\n",
      "  mean_raw_obs_processing_ms: 0.12213562853288389\n",
      "time_since_restore: 1583.602365732193\n",
      "time_this_iter_s: 37.50868082046509\n",
      "time_total_s: 1583.602365732193\n",
      "timers:\n",
      "  learn_throughput: 2134.73\n",
      "  learn_time_ms: 1873.773\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.986\n",
      "  sample_time_ms: 35718.596\n",
      "  update_time_ms: 1.73\n",
      "timestamp: 1633478203\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 168000\n",
      "training_iteration: 42\n",
      "\n",
      "agent_timesteps_total: 172000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-57-21\n",
      "done: false\n",
      "episode_len_mean: 870.4795918367347\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.47148480946302085\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 98\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.1956291198730469\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008269078098237514\n",
      "        model: {}\n",
      "        policy_loss: -0.008249729871749878\n",
      "        total_loss: -0.007354325149208307\n",
      "        vf_explained_var: 0.17059332132339478\n",
      "        vf_loss: 6.8498236942105e-05\n",
      "  num_agent_steps_sampled: 172000\n",
      "  num_agent_steps_trained: 172000\n",
      "  num_steps_sampled: 172000\n",
      "  num_steps_trained: 172000\n",
      "iterations_since_restore: 43\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.96415094339622\n",
      "  ram_util_percent: 36.59811320754716\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.060549439029769045\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.659507307384402\n",
      "  mean_inference_ms: 1.0795965438438824\n",
      "  mean_raw_obs_processing_ms: 0.12212805736399718\n",
      "time_since_restore: 1621.1282453536987\n",
      "time_this_iter_s: 37.52587962150574\n",
      "time_total_s: 1621.1282453536987\n",
      "timers:\n",
      "  learn_throughput: 2134.4\n",
      "  learn_time_ms: 1874.063\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.036\n",
      "  sample_time_ms: 35702.744\n",
      "  update_time_ms: 1.83\n",
      "timestamp: 1633478241\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 172000\n",
      "training_iteration: 43\n",
      "\n",
      "agent_timesteps_total: 176000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-57-59\n",
      "done: false\n",
      "episode_len_mean: 873.09\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.4751024888188616\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 100\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.1087563037872314\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01812324859201908\n",
      "        model: {}\n",
      "        policy_loss: -0.019255908206105232\n",
      "        total_loss: -0.017383074387907982\n",
      "        vf_explained_var: 0.14013931155204773\n",
      "        vf_loss: 6.050519732525572e-05\n",
      "  num_agent_steps_sampled: 176000\n",
      "  num_agent_steps_trained: 176000\n",
      "  num_steps_sampled: 176000\n",
      "  num_steps_trained: 176000\n",
      "iterations_since_restore: 44\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.009433962264144\n",
      "  ram_util_percent: 36.62264150943396\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06053804105286052\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.658722596491486\n",
      "  mean_inference_ms: 1.0795281201607319\n",
      "  mean_raw_obs_processing_ms: 0.12212162719048468\n",
      "time_since_restore: 1658.8081080913544\n",
      "time_this_iter_s: 37.67986273765564\n",
      "time_total_s: 1658.8081080913544\n",
      "timers:\n",
      "  learn_throughput: 2135.755\n",
      "  learn_time_ms: 1872.874\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.996\n",
      "  sample_time_ms: 35715.423\n",
      "  update_time_ms: 1.931\n",
      "timestamp: 1633478279\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 176000\n",
      "training_iteration: 44\n",
      "\n",
      "agent_timesteps_total: 180000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-58-37\n",
      "done: false\n",
      "episode_len_mean: 871.97\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.45588029700193206\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 102\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.0419138669967651\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010383452288806438\n",
      "        model: {}\n",
      "        policy_loss: -0.015148747712373734\n",
      "        total_loss: -0.01148470863699913\n",
      "        vf_explained_var: -0.4812048673629761\n",
      "        vf_loss: 0.00262569566257298\n",
      "  num_agent_steps_sampled: 180000\n",
      "  num_agent_steps_trained: 180000\n",
      "  num_steps_sampled: 180000\n",
      "  num_steps_trained: 180000\n",
      "iterations_since_restore: 45\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.41320754716982\n",
      "  ram_util_percent: 36.58867924528302\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06061881714698023\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.657070089270718\n",
      "  mean_inference_ms: 1.07905374934055\n",
      "  mean_raw_obs_processing_ms: 0.12227241601578143\n",
      "time_since_restore: 1696.6146035194397\n",
      "time_this_iter_s: 37.80649542808533\n",
      "time_total_s: 1696.6146035194397\n",
      "timers:\n",
      "  learn_throughput: 2124.573\n",
      "  learn_time_ms: 1882.731\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.947\n",
      "  sample_time_ms: 35731.211\n",
      "  update_time_ms: 1.931\n",
      "timestamp: 1633478317\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 180000\n",
      "training_iteration: 45\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 184000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-59-14\n",
      "done: false\n",
      "episode_len_mean: 865.86\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.4600814400322984\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 105\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.1031008958816528\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01106689590960741\n",
      "        model: {}\n",
      "        policy_loss: -0.008433178998529911\n",
      "        total_loss: -0.007099180482327938\n",
      "        vf_explained_var: -0.07062472403049469\n",
      "        vf_loss: 0.00022731187345925719\n",
      "  num_agent_steps_sampled: 184000\n",
      "  num_agent_steps_trained: 184000\n",
      "  num_steps_sampled: 184000\n",
      "  num_steps_trained: 184000\n",
      "iterations_since_restore: 46\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.017307692307693\n",
      "  ram_util_percent: 36.59423076923076\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06067507847816381\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.654159846277636\n",
      "  mean_inference_ms: 1.0786420602887814\n",
      "  mean_raw_obs_processing_ms: 0.12214970463101425\n",
      "time_since_restore: 1734.0883848667145\n",
      "time_this_iter_s: 37.47378134727478\n",
      "time_total_s: 1734.0883848667145\n",
      "timers:\n",
      "  learn_throughput: 2124.682\n",
      "  learn_time_ms: 1882.635\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.978\n",
      "  sample_time_ms: 35721.427\n",
      "  update_time_ms: 1.931\n",
      "timestamp: 1633478354\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 184000\n",
      "training_iteration: 46\n",
      "\n",
      "agent_timesteps_total: 188000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_08-59-52\n",
      "done: false\n",
      "episode_len_mean: 873.92\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.47890497524307685\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 107\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.162450909614563\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.018987419083714485\n",
      "        model: {}\n",
      "        policy_loss: -0.020859437063336372\n",
      "        total_loss: -0.018750380724668503\n",
      "        vf_explained_var: -0.055922981351614\n",
      "        vf_loss: 0.00021031674987170845\n",
      "  num_agent_steps_sampled: 188000\n",
      "  num_agent_steps_trained: 188000\n",
      "  num_steps_sampled: 188000\n",
      "  num_steps_trained: 188000\n",
      "iterations_since_restore: 47\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.307547169811325\n",
      "  ram_util_percent: 36.598113207547165\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0607016881463648\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.652044506472706\n",
      "  mean_inference_ms: 1.0783991922709728\n",
      "  mean_raw_obs_processing_ms: 0.12202581549718065\n",
      "time_since_restore: 1771.6076171398163\n",
      "time_this_iter_s: 37.51923227310181\n",
      "time_total_s: 1771.6076171398163\n",
      "timers:\n",
      "  learn_throughput: 2123.839\n",
      "  learn_time_ms: 1883.382\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.019\n",
      "  sample_time_ms: 35708.2\n",
      "  update_time_ms: 1.931\n",
      "timestamp: 1633478392\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 188000\n",
      "training_iteration: 47\n",
      "\n",
      "agent_timesteps_total: 192000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-00-29\n",
      "done: false\n",
      "episode_len_mean: 873.4\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.004604613922777\n",
      "episode_reward_mean: -0.4822301324171778\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 110\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.0841282606124878\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009875866584479809\n",
      "        model: {}\n",
      "        policy_loss: -0.015182527713477612\n",
      "        total_loss: -0.013892010785639286\n",
      "        vf_explained_var: -0.05755236744880676\n",
      "        vf_loss: 0.0003029255894944072\n",
      "  num_agent_steps_sampled: 192000\n",
      "  num_agent_steps_trained: 192000\n",
      "  num_steps_sampled: 192000\n",
      "  num_steps_trained: 192000\n",
      "iterations_since_restore: 48\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.501886792452833\n",
      "  ram_util_percent: 36.596226415094335\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06072521538334266\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.649213659550945\n",
      "  mean_inference_ms: 1.0780966357545267\n",
      "  mean_raw_obs_processing_ms: 0.12189652534545167\n",
      "time_since_restore: 1809.281878709793\n",
      "time_this_iter_s: 37.67426156997681\n",
      "time_total_s: 1809.281878709793\n",
      "timers:\n",
      "  learn_throughput: 2116.462\n",
      "  learn_time_ms: 1889.946\n",
      "  load_throughput: 40098508.604\n",
      "  load_time_ms: 0.1\n",
      "  sample_throughput: 112.042\n",
      "  sample_time_ms: 35700.986\n",
      "  update_time_ms: 1.911\n",
      "timestamp: 1633478429\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 192000\n",
      "training_iteration: 48\n",
      "\n",
      "agent_timesteps_total: 196000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-01-07\n",
      "done: false\n",
      "episode_len_mean: 875.28\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.5132856509453503\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 112\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.1364866495132446\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013081223703920841\n",
      "        model: {}\n",
      "        policy_loss: -0.0051962812431156635\n",
      "        total_loss: -0.003800423350185156\n",
      "        vf_explained_var: 0.033683568239212036\n",
      "        vf_loss: 8.77350103110075e-05\n",
      "  num_agent_steps_sampled: 196000\n",
      "  num_agent_steps_trained: 196000\n",
      "  num_steps_sampled: 196000\n",
      "  num_steps_trained: 196000\n",
      "iterations_since_restore: 49\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.049056603773586\n",
      "  ram_util_percent: 36.59811320754716\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0607456881999021\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.647224690685825\n",
      "  mean_inference_ms: 1.0778987786490033\n",
      "  mean_raw_obs_processing_ms: 0.12181855246183325\n",
      "time_since_restore: 1846.9067573547363\n",
      "time_this_iter_s: 37.62487864494324\n",
      "time_total_s: 1846.9067573547363\n",
      "timers:\n",
      "  learn_throughput: 2116.782\n",
      "  learn_time_ms: 1889.661\n",
      "  load_throughput: 40098508.604\n",
      "  load_time_ms: 0.1\n",
      "  sample_throughput: 112.082\n",
      "  sample_time_ms: 35688.133\n",
      "  update_time_ms: 1.918\n",
      "timestamp: 1633478467\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 196000\n",
      "training_iteration: 49\n",
      "\n",
      "agent_timesteps_total: 200000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-01-45\n",
      "done: false\n",
      "episode_len_mean: 867.3\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.4923428132953511\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 115\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.113231897354126\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0035695235710591078\n",
      "        model: {}\n",
      "        policy_loss: -0.0038020398933440447\n",
      "        total_loss: 0.00018576216825749725\n",
      "        vf_explained_var: -0.4149070680141449\n",
      "        vf_loss: 0.003630848368629813\n",
      "  num_agent_steps_sampled: 200000\n",
      "  num_agent_steps_trained: 200000\n",
      "  num_steps_sampled: 200000\n",
      "  num_steps_trained: 200000\n",
      "iterations_since_restore: 50\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 28.58679245283018\n",
      "  ram_util_percent: 36.60943396226415\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.060732341650032634\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.644666952983307\n",
      "  mean_inference_ms: 1.0776013923902403\n",
      "  mean_raw_obs_processing_ms: 0.12173854100548631\n",
      "time_since_restore: 1884.4930176734924\n",
      "time_this_iter_s: 37.5862603187561\n",
      "time_total_s: 1884.4930176734924\n",
      "timers:\n",
      "  learn_throughput: 2115.394\n",
      "  learn_time_ms: 1890.901\n",
      "  load_throughput: 40098508.604\n",
      "  load_time_ms: 0.1\n",
      "  sample_throughput: 112.058\n",
      "  sample_time_ms: 35695.777\n",
      "  update_time_ms: 1.918\n",
      "timestamp: 1633478505\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 200000\n",
      "training_iteration: 50\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 204000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-02-22\n",
      "done: false\n",
      "episode_len_mean: 865.38\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.5091471558870478\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 118\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.05000000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.1417089700698853\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011221732944250107\n",
      "        model: {}\n",
      "        policy_loss: -0.01189071498811245\n",
      "        total_loss: -0.011209061369299889\n",
      "        vf_explained_var: -0.08096714317798615\n",
      "        vf_loss: 0.00012056914420099929\n",
      "  num_agent_steps_sampled: 204000\n",
      "  num_agent_steps_trained: 204000\n",
      "  num_steps_sampled: 204000\n",
      "  num_steps_trained: 204000\n",
      "iterations_since_restore: 51\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.426923076923078\n",
      "  ram_util_percent: 36.61538461538461\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.060713842012850947\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.642229536184463\n",
      "  mean_inference_ms: 1.07734092847942\n",
      "  mean_raw_obs_processing_ms: 0.12167884583887512\n",
      "time_since_restore: 1921.994773387909\n",
      "time_this_iter_s: 37.501755714416504\n",
      "time_total_s: 1921.994773387909\n",
      "timers:\n",
      "  learn_throughput: 2112.584\n",
      "  learn_time_ms: 1893.416\n",
      "  load_throughput: 40098508.604\n",
      "  load_time_ms: 0.1\n",
      "  sample_throughput: 112.08\n",
      "  sample_time_ms: 35688.95\n",
      "  update_time_ms: 1.904\n",
      "timestamp: 1633478542\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 204000\n",
      "training_iteration: 51\n",
      "\n",
      "agent_timesteps_total: 208000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-03-00\n",
      "done: false\n",
      "episode_len_mean: 865.38\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.5128671844883725\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 120\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.05000000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.123657464981079\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02752467803657055\n",
      "        model: {}\n",
      "        policy_loss: -0.02322194166481495\n",
      "        total_loss: -0.021365508437156677\n",
      "        vf_explained_var: -0.19574116170406342\n",
      "        vf_loss: 0.000480200513266027\n",
      "  num_agent_steps_sampled: 208000\n",
      "  num_agent_steps_trained: 208000\n",
      "  num_steps_sampled: 208000\n",
      "  num_steps_trained: 208000\n",
      "iterations_since_restore: 52\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.45660377358491\n",
      "  ram_util_percent: 36.61132075471697\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.060693950332086306\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.640609122467882\n",
      "  mean_inference_ms: 1.077208642811712\n",
      "  mean_raw_obs_processing_ms: 0.12165971853718392\n",
      "time_since_restore: 1959.6775724887848\n",
      "time_this_iter_s: 37.682799100875854\n",
      "time_total_s: 1959.6775724887848\n",
      "timers:\n",
      "  learn_throughput: 2113.017\n",
      "  learn_time_ms: 1893.028\n",
      "  load_throughput: 40098508.604\n",
      "  load_time_ms: 0.1\n",
      "  sample_throughput: 112.024\n",
      "  sample_time_ms: 35706.67\n",
      "  update_time_ms: 1.904\n",
      "timestamp: 1633478580\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 208000\n",
      "training_iteration: 52\n",
      "\n",
      "agent_timesteps_total: 212000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-03-37\n",
      "done: false\n",
      "episode_len_mean: 862.88\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.5113884934875557\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 122\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.2004138231277466\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010635809041559696\n",
      "        model: {}\n",
      "        policy_loss: -0.015540992841124535\n",
      "        total_loss: -0.014611863531172276\n",
      "        vf_explained_var: 0.18830813467502594\n",
      "        vf_loss: 0.00013144250260666013\n",
      "  num_agent_steps_sampled: 212000\n",
      "  num_agent_steps_trained: 212000\n",
      "  num_steps_sampled: 212000\n",
      "  num_steps_trained: 212000\n",
      "iterations_since_restore: 53\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.20754716981132\n",
      "  ram_util_percent: 36.63584905660377\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06068248278865097\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.63924794163825\n",
      "  mean_inference_ms: 1.0770827306052828\n",
      "  mean_raw_obs_processing_ms: 0.12167447771717559\n",
      "time_since_restore: 1997.1236131191254\n",
      "time_this_iter_s: 37.446040630340576\n",
      "time_total_s: 1997.1236131191254\n",
      "timers:\n",
      "  learn_throughput: 2114.974\n",
      "  learn_time_ms: 1891.276\n",
      "  load_throughput: 40098508.604\n",
      "  load_time_ms: 0.1\n",
      "  sample_throughput: 112.043\n",
      "  sample_time_ms: 35700.427\n",
      "  update_time_ms: 1.904\n",
      "timestamp: 1633478617\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 212000\n",
      "training_iteration: 53\n",
      "\n",
      "agent_timesteps_total: 216000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-04-18\n",
      "done: false\n",
      "episode_len_mean: 863.51\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.5042216258347239\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 125\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.1808592081069946\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006530517712235451\n",
      "        model: {}\n",
      "        policy_loss: -0.007583847269415855\n",
      "        total_loss: -0.004588321782648563\n",
      "        vf_explained_var: -0.3838571012020111\n",
      "        vf_loss: 0.002505736192688346\n",
      "  num_agent_steps_sampled: 216000\n",
      "  num_agent_steps_trained: 216000\n",
      "  num_steps_sampled: 216000\n",
      "  num_steps_trained: 216000\n",
      "iterations_since_restore: 54\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.645614035087725\n",
      "  ram_util_percent: 37.18245614035088\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06066977156845328\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.637823540871864\n",
      "  mean_inference_ms: 1.0769738365218466\n",
      "  mean_raw_obs_processing_ms: 0.12171351396036928\n",
      "time_since_restore: 2037.734604358673\n",
      "time_this_iter_s: 40.61099123954773\n",
      "time_total_s: 2037.734604358673\n",
      "timers:\n",
      "  learn_throughput: 2063.655\n",
      "  learn_time_ms: 1938.308\n",
      "  load_throughput: 40098508.604\n",
      "  load_time_ms: 0.1\n",
      "  sample_throughput: 111.277\n",
      "  sample_time_ms: 35946.285\n",
      "  update_time_ms: 1.902\n",
      "timestamp: 1633478658\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 216000\n",
      "training_iteration: 54\n",
      "\n",
      "agent_timesteps_total: 220000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-04-57\n",
      "done: false\n",
      "episode_len_mean: 867.27\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.5086638733600128\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 127\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.2186379432678223\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010254552587866783\n",
      "        model: {}\n",
      "        policy_loss: -0.010034125298261642\n",
      "        total_loss: -0.008164161816239357\n",
      "        vf_explained_var: -0.4277425706386566\n",
      "        vf_loss: 0.0011008715955540538\n",
      "  num_agent_steps_sampled: 220000\n",
      "  num_agent_steps_trained: 220000\n",
      "  num_steps_sampled: 220000\n",
      "  num_steps_trained: 220000\n",
      "iterations_since_restore: 55\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.13454545454545\n",
      "  ram_util_percent: 39.27818181818182\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06064993227280016\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.636940031565786\n",
      "  mean_inference_ms: 1.076917330039789\n",
      "  mean_raw_obs_processing_ms: 0.12174878885559526\n",
      "time_since_restore: 2076.411695957184\n",
      "time_this_iter_s: 38.67709159851074\n",
      "time_total_s: 2076.411695957184\n",
      "timers:\n",
      "  learn_throughput: 2080.337\n",
      "  learn_time_ms: 1922.766\n",
      "  load_throughput: 40098508.604\n",
      "  load_time_ms: 0.1\n",
      "  sample_throughput: 110.96\n",
      "  sample_time_ms: 36048.928\n",
      "  update_time_ms: 1.902\n",
      "timestamp: 1633478697\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 220000\n",
      "training_iteration: 55\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 224000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-05-34\n",
      "done: false\n",
      "episode_len_mean: 860.55\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.512434330390104\n",
      "episode_reward_min: -0.8290607906842784\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 129\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.2117866277694702\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01192597858607769\n",
      "        model: {}\n",
      "        policy_loss: -0.015088692307472229\n",
      "        total_loss: -0.014033104293048382\n",
      "        vf_explained_var: -0.26238709688186646\n",
      "        vf_loss: 0.00016114325262606144\n",
      "  num_agent_steps_sampled: 224000\n",
      "  num_agent_steps_trained: 224000\n",
      "  num_steps_sampled: 224000\n",
      "  num_steps_trained: 224000\n",
      "iterations_since_restore: 56\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.321153846153848\n",
      "  ram_util_percent: 39.47115384615385\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06062810012749354\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.636000740089802\n",
      "  mean_inference_ms: 1.0768677893468734\n",
      "  mean_raw_obs_processing_ms: 0.12177188057660543\n",
      "time_since_restore: 2113.851681470871\n",
      "time_this_iter_s: 37.439985513687134\n",
      "time_total_s: 2113.851681470871\n",
      "timers:\n",
      "  learn_throughput: 2078.274\n",
      "  learn_time_ms: 1924.674\n",
      "  load_throughput: 40098508.604\n",
      "  load_time_ms: 0.1\n",
      "  sample_throughput: 110.977\n",
      "  sample_time_ms: 36043.666\n",
      "  update_time_ms: 1.904\n",
      "timestamp: 1633478734\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 224000\n",
      "training_iteration: 56\n",
      "\n",
      "agent_timesteps_total: 228000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-06-12\n",
      "done: false\n",
      "episode_len_mean: 863.31\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.5058800950792502\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 132\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.106176733970642\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006445889826864004\n",
      "        model: {}\n",
      "        policy_loss: -0.007242834661155939\n",
      "        total_loss: -0.002594542223960161\n",
      "        vf_explained_var: 0.041951000690460205\n",
      "        vf_loss: 0.004164851736277342\n",
      "  num_agent_steps_sampled: 228000\n",
      "  num_agent_steps_trained: 228000\n",
      "  num_steps_sampled: 228000\n",
      "  num_steps_trained: 228000\n",
      "iterations_since_restore: 57\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.647169811320754\n",
      "  ram_util_percent: 39.43773584905661\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0605954046597297\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.634636545916226\n",
      "  mean_inference_ms: 1.0768048488275608\n",
      "  mean_raw_obs_processing_ms: 0.12180482911046721\n",
      "time_since_restore: 2151.3845567703247\n",
      "time_this_iter_s: 37.532875299453735\n",
      "time_total_s: 2151.3845567703247\n",
      "timers:\n",
      "  learn_throughput: 2080.004\n",
      "  learn_time_ms: 1923.073\n",
      "  load_throughput: 40098508.604\n",
      "  load_time_ms: 0.1\n",
      "  sample_throughput: 110.967\n",
      "  sample_time_ms: 36046.676\n",
      "  update_time_ms: 1.904\n",
      "timestamp: 1633478772\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 228000\n",
      "training_iteration: 57\n",
      "\n",
      "agent_timesteps_total: 232000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-06-49\n",
      "done: false\n",
      "episode_len_mean: 863.21\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.5079900492979563\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 134\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.143435001373291\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016524245962500572\n",
      "        model: {}\n",
      "        policy_loss: -0.019127830862998962\n",
      "        total_loss: -0.017810780555009842\n",
      "        vf_explained_var: 0.20899903774261475\n",
      "        vf_loss: 7.773286779411137e-05\n",
      "  num_agent_steps_sampled: 232000\n",
      "  num_agent_steps_trained: 232000\n",
      "  num_steps_sampled: 232000\n",
      "  num_steps_trained: 232000\n",
      "iterations_since_restore: 58\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.826415094339627\n",
      "  ram_util_percent: 39.43584905660378\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06058130260005672\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.633839825732288\n",
      "  mean_inference_ms: 1.0767663740157931\n",
      "  mean_raw_obs_processing_ms: 0.12182320677585551\n",
      "time_since_restore: 2188.985503435135\n",
      "time_this_iter_s: 37.60094666481018\n",
      "time_total_s: 2188.985503435135\n",
      "timers:\n",
      "  learn_throughput: 2076.293\n",
      "  learn_time_ms: 1926.511\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.0\n",
      "  sample_time_ms: 36035.909\n",
      "  update_time_ms: 1.904\n",
      "timestamp: 1633478809\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 232000\n",
      "training_iteration: 58\n",
      "\n",
      "agent_timesteps_total: 236000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-07-27\n",
      "done: false\n",
      "episode_len_mean: 863.31\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.5109375394595752\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 136\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.1192718744277954\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011442880146205425\n",
      "        model: {}\n",
      "        policy_loss: -0.012403317727148533\n",
      "        total_loss: -0.011295429430902004\n",
      "        vf_explained_var: -0.09849489480257034\n",
      "        vf_loss: 0.00024967084755189717\n",
      "  num_agent_steps_sampled: 236000\n",
      "  num_agent_steps_trained: 236000\n",
      "  num_steps_sampled: 236000\n",
      "  num_steps_trained: 236000\n",
      "iterations_since_restore: 59\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.513207547169813\n",
      "  ram_util_percent: 39.43962264150944\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06056773455008411\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.633053450415673\n",
      "  mean_inference_ms: 1.076740102836687\n",
      "  mean_raw_obs_processing_ms: 0.12184968880156993\n",
      "time_since_restore: 2226.5906693935394\n",
      "time_this_iter_s: 37.60516595840454\n",
      "time_total_s: 2226.5906693935394\n",
      "timers:\n",
      "  learn_throughput: 2070.023\n",
      "  learn_time_ms: 1932.346\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.024\n",
      "  sample_time_ms: 36028.208\n",
      "  update_time_ms: 2.061\n",
      "timestamp: 1633478847\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 236000\n",
      "training_iteration: 59\n",
      "\n",
      "agent_timesteps_total: 240000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-08-04\n",
      "done: false\n",
      "episode_len_mean: 864.34\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.5140334467937222\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 138\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.1020398139953613\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007804451044648886\n",
      "        model: {}\n",
      "        policy_loss: -0.03308301046490669\n",
      "        total_loss: -0.03228005766868591\n",
      "        vf_explained_var: 0.1300724595785141\n",
      "        vf_loss: 0.0002176168782170862\n",
      "  num_agent_steps_sampled: 240000\n",
      "  num_agent_steps_trained: 240000\n",
      "  num_steps_sampled: 240000\n",
      "  num_steps_trained: 240000\n",
      "iterations_since_restore: 60\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.549056603773582\n",
      "  ram_util_percent: 39.464150943396234\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06055570632740634\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.63228347079364\n",
      "  mean_inference_ms: 1.076712532566876\n",
      "  mean_raw_obs_processing_ms: 0.12188014050678393\n",
      "time_since_restore: 2264.2497913837433\n",
      "time_this_iter_s: 37.65912199020386\n",
      "time_total_s: 2264.2497913837433\n",
      "timers:\n",
      "  learn_throughput: 2069.397\n",
      "  learn_time_ms: 1932.93\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.003\n",
      "  sample_time_ms: 36034.997\n",
      "  update_time_ms: 1.962\n",
      "timestamp: 1633478884\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 240000\n",
      "training_iteration: 60\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 244000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-08-42\n",
      "done: false\n",
      "episode_len_mean: 869.09\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.521590301825994\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 141\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.0079405307769775\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01098707690834999\n",
      "        model: {}\n",
      "        policy_loss: -0.01662864349782467\n",
      "        total_loss: -0.015716226771473885\n",
      "        vf_explained_var: 0.15457962453365326\n",
      "        vf_loss: 8.838748908601701e-05\n",
      "  num_agent_steps_sampled: 244000\n",
      "  num_agent_steps_trained: 244000\n",
      "  num_steps_sampled: 244000\n",
      "  num_steps_trained: 244000\n",
      "iterations_since_restore: 61\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 24.28076923076923\n",
      "  ram_util_percent: 39.46538461538462\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06053854939264264\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.631188482941724\n",
      "  mean_inference_ms: 1.0766813444525265\n",
      "  mean_raw_obs_processing_ms: 0.12194183768790179\n",
      "time_since_restore: 2301.6593811511993\n",
      "time_this_iter_s: 37.409589767456055\n",
      "time_total_s: 2301.6593811511993\n",
      "timers:\n",
      "  learn_throughput: 2072.415\n",
      "  learn_time_ms: 1930.115\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.023\n",
      "  sample_time_ms: 36028.641\n",
      "  update_time_ms: 1.892\n",
      "timestamp: 1633478922\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 244000\n",
      "training_iteration: 61\n",
      "\n",
      "agent_timesteps_total: 248000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-09-19\n",
      "done: false\n",
      "episode_len_mean: 860.01\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.5172082879000918\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 144\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.0705937147140503\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012078901752829552\n",
      "        model: {}\n",
      "        policy_loss: -0.014410053379833698\n",
      "        total_loss: -0.013364344835281372\n",
      "        vf_explained_var: -0.16010954976081848\n",
      "        vf_loss: 0.00013978696370031685\n",
      "  num_agent_steps_sampled: 248000\n",
      "  num_agent_steps_trained: 248000\n",
      "  num_steps_sampled: 248000\n",
      "  num_steps_trained: 248000\n",
      "iterations_since_restore: 62\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.645283018867925\n",
      "  ram_util_percent: 39.45660377358491\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.060526365167951415\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.630232949548972\n",
      "  mean_inference_ms: 1.0766614207151084\n",
      "  mean_raw_obs_processing_ms: 0.12200862832502984\n",
      "time_since_restore: 2339.178837299347\n",
      "time_this_iter_s: 37.51945614814758\n",
      "time_total_s: 2339.178837299347\n",
      "timers:\n",
      "  learn_throughput: 2073.047\n",
      "  learn_time_ms: 1929.527\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.072\n",
      "  sample_time_ms: 36012.833\n",
      "  update_time_ms: 1.793\n",
      "timestamp: 1633478959\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 248000\n",
      "training_iteration: 62\n",
      "\n",
      "agent_timesteps_total: 252000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-09-57\n",
      "done: false\n",
      "episode_len_mean: 856.62\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.5164523276706052\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 147\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.0483821630477905\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012222286313772202\n",
      "        model: {}\n",
      "        policy_loss: -0.013827803544700146\n",
      "        total_loss: -0.012819948606193066\n",
      "        vf_explained_var: 0.2660983204841614\n",
      "        vf_loss: 9.11845636437647e-05\n",
      "  num_agent_steps_sampled: 252000\n",
      "  num_agent_steps_trained: 252000\n",
      "  num_steps_sampled: 252000\n",
      "  num_steps_trained: 252000\n",
      "iterations_since_restore: 63\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 28.313207547169814\n",
      "  ram_util_percent: 39.43018867924528\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06051526777913843\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.629414952051608\n",
      "  mean_inference_ms: 1.0766485263332444\n",
      "  mean_raw_obs_processing_ms: 0.12206446881291708\n",
      "time_since_restore: 2376.7649443149567\n",
      "time_this_iter_s: 37.58610701560974\n",
      "time_total_s: 2376.7649443149567\n",
      "timers:\n",
      "  learn_throughput: 2064.042\n",
      "  learn_time_ms: 1937.945\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.055\n",
      "  sample_time_ms: 36018.288\n",
      "  update_time_ms: 1.77\n",
      "timestamp: 1633478997\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 252000\n",
      "training_iteration: 63\n",
      "\n",
      "agent_timesteps_total: 256000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-10-34\n",
      "done: false\n",
      "episode_len_mean: 853.64\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.5131960106668733\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 149\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9924685955047607\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01379200629889965\n",
      "        model: {}\n",
      "        policy_loss: -0.021607326343655586\n",
      "        total_loss: -0.020487995818257332\n",
      "        vf_explained_var: 0.37853628396987915\n",
      "        vf_loss: 8.492894266964868e-05\n",
      "  num_agent_steps_sampled: 256000\n",
      "  num_agent_steps_trained: 256000\n",
      "  num_steps_sampled: 256000\n",
      "  num_steps_trained: 256000\n",
      "iterations_since_restore: 64\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.662264150943393\n",
      "  ram_util_percent: 39.42075471698114\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06050919586412628\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.628924741429824\n",
      "  mean_inference_ms: 1.0766320727295255\n",
      "  mean_raw_obs_processing_ms: 0.12210344394911242\n",
      "time_since_restore: 2414.1948142051697\n",
      "time_this_iter_s: 37.42986989021301\n",
      "time_total_s: 2414.1948142051697\n",
      "timers:\n",
      "  learn_throughput: 2114.594\n",
      "  learn_time_ms: 1891.616\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.898\n",
      "  sample_time_ms: 35746.931\n",
      "  update_time_ms: 1.671\n",
      "timestamp: 1633479034\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 256000\n",
      "training_iteration: 64\n",
      "\n",
      "agent_timesteps_total: 260000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-11-12\n",
      "done: false\n",
      "episode_len_mean: 849.14\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.5114384341814817\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 152\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.987280547618866\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008372028358280659\n",
      "        model: {}\n",
      "        policy_loss: -0.012349734082818031\n",
      "        total_loss: -0.011645655147731304\n",
      "        vf_explained_var: 0.2625305950641632\n",
      "        vf_loss: 7.617363007739186e-05\n",
      "  num_agent_steps_sampled: 260000\n",
      "  num_agent_steps_trained: 260000\n",
      "  num_steps_sampled: 260000\n",
      "  num_steps_trained: 260000\n",
      "iterations_since_restore: 65\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.89230769230769\n",
      "  ram_util_percent: 39.4423076923077\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06049472146741637\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.628175295094273\n",
      "  mean_inference_ms: 1.0766052740397527\n",
      "  mean_raw_obs_processing_ms: 0.12213788068078682\n",
      "time_since_restore: 2451.7164902687073\n",
      "time_this_iter_s: 37.5216760635376\n",
      "time_total_s: 2451.7164902687073\n",
      "timers:\n",
      "  learn_throughput: 2116.037\n",
      "  learn_time_ms: 1890.326\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.257\n",
      "  sample_time_ms: 35632.574\n",
      "  update_time_ms: 1.67\n",
      "timestamp: 1633479072\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 260000\n",
      "training_iteration: 65\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 264000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-11-50\n",
      "done: false\n",
      "episode_len_mean: 847.5\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.511698164375429\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 155\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9694123268127441\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008905167691409588\n",
      "        model: {}\n",
      "        policy_loss: -0.011059338226914406\n",
      "        total_loss: -0.010330070741474628\n",
      "        vf_explained_var: 0.18356887996196747\n",
      "        vf_loss: 6.137796299299225e-05\n",
      "  num_agent_steps_sampled: 264000\n",
      "  num_agent_steps_trained: 264000\n",
      "  num_steps_sampled: 264000\n",
      "  num_steps_trained: 264000\n",
      "iterations_since_restore: 66\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.100000000000005\n",
      "  ram_util_percent: 39.43396226415094\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06049717133584995\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.627482988835418\n",
      "  mean_inference_ms: 1.0765739418136067\n",
      "  mean_raw_obs_processing_ms: 0.12215932609099654\n",
      "time_since_restore: 2489.2681839466095\n",
      "time_this_iter_s: 37.55169367790222\n",
      "time_total_s: 2489.2681839466095\n",
      "timers:\n",
      "  learn_throughput: 2114.928\n",
      "  learn_time_ms: 1891.317\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.224\n",
      "  sample_time_ms: 35642.878\n",
      "  update_time_ms: 1.569\n",
      "timestamp: 1633479110\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 264000\n",
      "training_iteration: 66\n",
      "\n",
      "agent_timesteps_total: 268000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-12-27\n",
      "done: false\n",
      "episode_len_mean: 840.9\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.5075851103960326\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 157\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9171959161758423\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007017906755208969\n",
      "        model: {}\n",
      "        policy_loss: -0.006379901897162199\n",
      "        total_loss: -0.005747543647885323\n",
      "        vf_explained_var: 0.008966338820755482\n",
      "        vf_loss: 0.00010601329267956316\n",
      "  num_agent_steps_sampled: 268000\n",
      "  num_agent_steps_trained: 268000\n",
      "  num_steps_sampled: 268000\n",
      "  num_steps_trained: 268000\n",
      "iterations_since_restore: 67\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.167924528301885\n",
      "  ram_util_percent: 39.422641509433966\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0605038135739721\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.627034120326435\n",
      "  mean_inference_ms: 1.0765495785150423\n",
      "  mean_raw_obs_processing_ms: 0.12217079316670791\n",
      "time_since_restore: 2526.6499321460724\n",
      "time_this_iter_s: 37.38174819946289\n",
      "time_total_s: 2526.6499321460724\n",
      "timers:\n",
      "  learn_throughput: 2113.537\n",
      "  learn_time_ms: 1892.562\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.276\n",
      "  sample_time_ms: 35626.599\n",
      "  update_time_ms: 1.569\n",
      "timestamp: 1633479147\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 268000\n",
      "training_iteration: 67\n",
      "\n",
      "agent_timesteps_total: 272000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-13-05\n",
      "done: false\n",
      "episode_len_mean: 841.44\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.5045804891362071\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 160\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9298366904258728\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010998539626598358\n",
      "        model: {}\n",
      "        policy_loss: -0.018037697300314903\n",
      "        total_loss: -0.017110047861933708\n",
      "        vf_explained_var: 0.19456063210964203\n",
      "        vf_loss: 0.0001027645921567455\n",
      "  num_agent_steps_sampled: 272000\n",
      "  num_agent_steps_trained: 272000\n",
      "  num_steps_sampled: 272000\n",
      "  num_steps_trained: 272000\n",
      "iterations_since_restore: 68\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.599999999999998\n",
      "  ram_util_percent: 39.44716981132076\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06052278398159082\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.626424893041072\n",
      "  mean_inference_ms: 1.0765251205790902\n",
      "  mean_raw_obs_processing_ms: 0.12218540214462066\n",
      "time_since_restore: 2564.390214920044\n",
      "time_this_iter_s: 37.74028277397156\n",
      "time_total_s: 2564.390214920044\n",
      "timers:\n",
      "  learn_throughput: 2122.115\n",
      "  learn_time_ms: 1884.912\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.208\n",
      "  sample_time_ms: 35648.126\n",
      "  update_time_ms: 1.569\n",
      "timestamp: 1633479185\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 272000\n",
      "training_iteration: 68\n",
      "\n",
      "agent_timesteps_total: 276000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-13-42\n",
      "done: false\n",
      "episode_len_mean: 841.71\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.5154253722283337\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 162\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.0636374950408936\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013778623193502426\n",
      "        model: {}\n",
      "        policy_loss: -0.013527384027838707\n",
      "        total_loss: -0.012391775846481323\n",
      "        vf_explained_var: 0.2584569752216339\n",
      "        vf_loss: 0.00010221216507488862\n",
      "  num_agent_steps_sampled: 276000\n",
      "  num_agent_steps_trained: 276000\n",
      "  num_steps_sampled: 276000\n",
      "  num_steps_trained: 276000\n",
      "iterations_since_restore: 69\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.509615384615383\n",
      "  ram_util_percent: 39.49807692307692\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06053261348192599\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.626036065352586\n",
      "  mean_inference_ms: 1.0765189281837921\n",
      "  mean_raw_obs_processing_ms: 0.12219022927931039\n",
      "time_since_restore: 2601.882397890091\n",
      "time_this_iter_s: 37.492182970047\n",
      "time_total_s: 2601.882397890091\n",
      "timers:\n",
      "  learn_throughput: 2129.716\n",
      "  learn_time_ms: 1878.185\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.222\n",
      "  sample_time_ms: 35643.505\n",
      "  update_time_ms: 1.504\n",
      "timestamp: 1633479222\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 276000\n",
      "training_iteration: 69\n",
      "\n",
      "agent_timesteps_total: 280000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-14-20\n",
      "done: false\n",
      "episode_len_mean: 837.33\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.5148481195475977\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 165\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9215652346611023\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014577646739780903\n",
      "        model: {}\n",
      "        policy_loss: -0.014342667534947395\n",
      "        total_loss: -0.013162021525204182\n",
      "        vf_explained_var: 0.0738038420677185\n",
      "        vf_loss: 8.73256431077607e-05\n",
      "  num_agent_steps_sampled: 280000\n",
      "  num_agent_steps_trained: 280000\n",
      "  num_steps_sampled: 280000\n",
      "  num_steps_trained: 280000\n",
      "iterations_since_restore: 70\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.666037735849052\n",
      "  ram_util_percent: 39.462264150943405\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.060557147029193924\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.625470351912906\n",
      "  mean_inference_ms: 1.0765143279606186\n",
      "  mean_raw_obs_processing_ms: 0.1221984042573976\n",
      "time_since_restore: 2639.589446783066\n",
      "time_this_iter_s: 37.70704889297485\n",
      "time_total_s: 2639.589446783066\n",
      "timers:\n",
      "  learn_throughput: 2124.63\n",
      "  learn_time_ms: 1882.681\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.222\n",
      "  sample_time_ms: 35643.767\n",
      "  update_time_ms: 1.604\n",
      "timestamp: 1633479260\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 280000\n",
      "training_iteration: 70\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 284000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-14-58\n",
      "done: false\n",
      "episode_len_mean: 826.4\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.5046786094710608\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 168\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.8151650428771973\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008646282367408276\n",
      "        model: {}\n",
      "        policy_loss: -0.017111122608184814\n",
      "        total_loss: -0.01634538732469082\n",
      "        vf_explained_var: 0.1651208996772766\n",
      "        vf_loss: 0.00011726153024937958\n",
      "  num_agent_steps_sampled: 284000\n",
      "  num_agent_steps_trained: 284000\n",
      "  num_steps_sampled: 284000\n",
      "  num_steps_trained: 284000\n",
      "iterations_since_restore: 71\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.64150943396227\n",
      "  ram_util_percent: 39.43962264150944\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06058019041538985\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.624930517819934\n",
      "  mean_inference_ms: 1.0765286392353832\n",
      "  mean_raw_obs_processing_ms: 0.12220335542619035\n",
      "time_since_restore: 2677.1879913806915\n",
      "time_this_iter_s: 37.59854459762573\n",
      "time_total_s: 2677.1879913806915\n",
      "timers:\n",
      "  learn_throughput: 2122.9\n",
      "  learn_time_ms: 1884.215\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.167\n",
      "  sample_time_ms: 35661.103\n",
      "  update_time_ms: 1.673\n",
      "timestamp: 1633479298\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 284000\n",
      "training_iteration: 71\n",
      "\n",
      "agent_timesteps_total: 288000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-15-35\n",
      "done: false\n",
      "episode_len_mean: 824.39\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.5025054826796008\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 170\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9770607352256775\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012228916399180889\n",
      "        model: {}\n",
      "        policy_loss: -0.022800114005804062\n",
      "        total_loss: -0.021759729832410812\n",
      "        vf_explained_var: 0.28171077370643616\n",
      "        vf_loss: 0.00012321244867052883\n",
      "  num_agent_steps_sampled: 288000\n",
      "  num_agent_steps_trained: 288000\n",
      "  num_steps_sampled: 288000\n",
      "  num_steps_trained: 288000\n",
      "iterations_since_restore: 72\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.039622641509435\n",
      "  ram_util_percent: 39.45283018867925\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06058780053830363\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.62460298243621\n",
      "  mean_inference_ms: 1.0765414941145028\n",
      "  mean_raw_obs_processing_ms: 0.12220789543454559\n",
      "time_since_restore: 2714.8676085472107\n",
      "time_this_iter_s: 37.679617166519165\n",
      "time_total_s: 2714.8676085472107\n",
      "timers:\n",
      "  learn_throughput: 2123.871\n",
      "  learn_time_ms: 1883.353\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.114\n",
      "  sample_time_ms: 35678.129\n",
      "  update_time_ms: 1.78\n",
      "timestamp: 1633479335\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 288000\n",
      "training_iteration: 72\n",
      "\n",
      "agent_timesteps_total: 292000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-16-13\n",
      "done: false\n",
      "episode_len_mean: 824.27\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.5025756556201479\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 172\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9405765533447266\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0116594722494483\n",
      "        model: {}\n",
      "        policy_loss: -0.005458686035126448\n",
      "        total_loss: -0.004505830351263285\n",
      "        vf_explained_var: 0.2288637012243271\n",
      "        vf_loss: 7.839399768272415e-05\n",
      "  num_agent_steps_sampled: 292000\n",
      "  num_agent_steps_trained: 292000\n",
      "  num_steps_sampled: 292000\n",
      "  num_steps_trained: 292000\n",
      "iterations_since_restore: 73\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 28.16481481481482\n",
      "  ram_util_percent: 39.437037037037044\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.060593294174303106\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.624335898001032\n",
      "  mean_inference_ms: 1.0765584540121031\n",
      "  mean_raw_obs_processing_ms: 0.12221168720206144\n",
      "time_since_restore: 2752.7302775382996\n",
      "time_this_iter_s: 37.86266899108887\n",
      "time_total_s: 2752.7302775382996\n",
      "timers:\n",
      "  learn_throughput: 2123.034\n",
      "  learn_time_ms: 1884.096\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.029\n",
      "  sample_time_ms: 35705.061\n",
      "  update_time_ms: 1.803\n",
      "timestamp: 1633479373\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 292000\n",
      "training_iteration: 73\n",
      "\n",
      "agent_timesteps_total: 296000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-16-51\n",
      "done: false\n",
      "episode_len_mean: 817.71\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.4953655382515987\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 175\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9618864059448242\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009833007119596004\n",
      "        model: {}\n",
      "        policy_loss: -0.014771297574043274\n",
      "        total_loss: -0.013983886688947678\n",
      "        vf_explained_var: 0.24962563812732697\n",
      "        vf_loss: 4.9935282731894404e-05\n",
      "  num_agent_steps_sampled: 296000\n",
      "  num_agent_steps_trained: 296000\n",
      "  num_steps_sampled: 296000\n",
      "  num_steps_trained: 296000\n",
      "iterations_since_restore: 74\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 24.553846153846152\n",
      "  ram_util_percent: 39.43076923076924\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.060604958984029594\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.62393999379019\n",
      "  mean_inference_ms: 1.0765883803121554\n",
      "  mean_raw_obs_processing_ms: 0.12221043750996446\n",
      "time_since_restore: 2790.2274539470673\n",
      "time_this_iter_s: 37.4971764087677\n",
      "time_total_s: 2790.2274539470673\n",
      "timers:\n",
      "  learn_throughput: 2123.448\n",
      "  learn_time_ms: 1883.728\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.007\n",
      "  sample_time_ms: 35712.103\n",
      "  update_time_ms: 1.902\n",
      "timestamp: 1633479411\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 296000\n",
      "training_iteration: 74\n",
      "\n",
      "agent_timesteps_total: 300000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-17-28\n",
      "done: false\n",
      "episode_len_mean: 813.17\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.4829399515216661\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 178\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9792309403419495\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0075623104348778725\n",
      "        model: {}\n",
      "        policy_loss: -0.006454735528677702\n",
      "        total_loss: -0.0024041500873863697\n",
      "        vf_explained_var: -0.6100901365280151\n",
      "        vf_loss: 0.0034834144171327353\n",
      "  num_agent_steps_sampled: 300000\n",
      "  num_agent_steps_trained: 300000\n",
      "  num_steps_sampled: 300000\n",
      "  num_steps_trained: 300000\n",
      "iterations_since_restore: 75\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.58301886792453\n",
      "  ram_util_percent: 39.4433962264151\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06060937012857388\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.623616601953632\n",
      "  mean_inference_ms: 1.076632391286728\n",
      "  mean_raw_obs_processing_ms: 0.12219730783231539\n",
      "time_since_restore: 2827.7697763442993\n",
      "time_this_iter_s: 37.542322397232056\n",
      "time_total_s: 2827.7697763442993\n",
      "timers:\n",
      "  learn_throughput: 2123.656\n",
      "  learn_time_ms: 1883.544\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.0\n",
      "  sample_time_ms: 35714.265\n",
      "  update_time_ms: 1.902\n",
      "timestamp: 1633479448\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 300000\n",
      "training_iteration: 75\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 304000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-18-06\n",
      "done: false\n",
      "episode_len_mean: 810.65\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.4821286674812831\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 180\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9830211997032166\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01167269703000784\n",
      "        model: {}\n",
      "        policy_loss: -0.020663857460021973\n",
      "        total_loss: -0.019554050639271736\n",
      "        vf_explained_var: 0.012141850776970387\n",
      "        vf_loss: 0.0002343551896046847\n",
      "  num_agent_steps_sampled: 304000\n",
      "  num_agent_steps_trained: 304000\n",
      "  num_steps_sampled: 304000\n",
      "  num_steps_trained: 304000\n",
      "iterations_since_restore: 76\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 28.594339622641503\n",
      "  ram_util_percent: 39.45471698113208\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06061210554141374\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.623437955324253\n",
      "  mean_inference_ms: 1.0766627534581428\n",
      "  mean_raw_obs_processing_ms: 0.12219030564001969\n",
      "time_since_restore: 2865.3194262981415\n",
      "time_this_iter_s: 37.54964995384216\n",
      "time_total_s: 2865.3194262981415\n",
      "timers:\n",
      "  learn_throughput: 2126.399\n",
      "  learn_time_ms: 1881.114\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.993\n",
      "  sample_time_ms: 35716.434\n",
      "  update_time_ms: 2.003\n",
      "timestamp: 1633479486\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 304000\n",
      "training_iteration: 76\n",
      "\n",
      "agent_timesteps_total: 308000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-18-43\n",
      "done: false\n",
      "episode_len_mean: 805.99\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.48053933030576773\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 183\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.927915632724762\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013609695248305798\n",
      "        model: {}\n",
      "        policy_loss: -0.018337931483983994\n",
      "        total_loss: -0.0171810332685709\n",
      "        vf_explained_var: 0.023573126643896103\n",
      "        vf_loss: 0.00013616924115922302\n",
      "  num_agent_steps_sampled: 308000\n",
      "  num_agent_steps_trained: 308000\n",
      "  num_steps_sampled: 308000\n",
      "  num_steps_trained: 308000\n",
      "iterations_since_restore: 77\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.569230769230764\n",
      "  ram_util_percent: 39.45384615384616\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06061770370204588\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.623133791925515\n",
      "  mean_inference_ms: 1.0767137450087785\n",
      "  mean_raw_obs_processing_ms: 0.12218409631652262\n",
      "time_since_restore: 2902.72953248024\n",
      "time_this_iter_s: 37.41010618209839\n",
      "time_total_s: 2902.72953248024\n",
      "timers:\n",
      "  learn_throughput: 2123.194\n",
      "  learn_time_ms: 1883.954\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.994\n",
      "  sample_time_ms: 35716.321\n",
      "  update_time_ms: 2.003\n",
      "timestamp: 1633479523\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 308000\n",
      "training_iteration: 77\n",
      "\n",
      "agent_timesteps_total: 312000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-19-21\n",
      "done: false\n",
      "episode_len_mean: 800.05\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.4806681746081062\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 186\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9116692543029785\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011934340000152588\n",
      "        model: {}\n",
      "        policy_loss: -0.01613120175898075\n",
      "        total_loss: -0.01513268705457449\n",
      "        vf_explained_var: 0.2648520767688751\n",
      "        vf_loss: 0.00010343886242480949\n",
      "  num_agent_steps_sampled: 312000\n",
      "  num_agent_steps_trained: 312000\n",
      "  num_steps_sampled: 312000\n",
      "  num_steps_trained: 312000\n",
      "iterations_since_restore: 78\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.437735849056608\n",
      "  ram_util_percent: 39.44905660377359\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06062211188593554\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.622816415982026\n",
      "  mean_inference_ms: 1.0767648207970408\n",
      "  mean_raw_obs_processing_ms: 0.12217937935348532\n",
      "time_since_restore: 2940.2837958335876\n",
      "time_this_iter_s: 37.55426335334778\n",
      "time_total_s: 2940.2837958335876\n",
      "timers:\n",
      "  learn_throughput: 2128.094\n",
      "  learn_time_ms: 1879.616\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.038\n",
      "  sample_time_ms: 35702.052\n",
      "  update_time_ms: 2.003\n",
      "timestamp: 1633479561\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 312000\n",
      "training_iteration: 78\n",
      "\n",
      "agent_timesteps_total: 316000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-19-58\n",
      "done: false\n",
      "episode_len_mean: 795.22\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.47796094921495225\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 188\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.8955107927322388\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009836924262344837\n",
      "        model: {}\n",
      "        policy_loss: -0.015900738537311554\n",
      "        total_loss: -0.015065189450979233\n",
      "        vf_explained_var: -0.006306680850684643\n",
      "        vf_loss: 9.777757077245042e-05\n",
      "  num_agent_steps_sampled: 316000\n",
      "  num_agent_steps_trained: 316000\n",
      "  num_steps_sampled: 316000\n",
      "  num_steps_trained: 316000\n",
      "iterations_since_restore: 79\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.799999999999997\n",
      "  ram_util_percent: 39.4433962264151\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06062672053389398\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.622590546170276\n",
      "  mean_inference_ms: 1.07679104368098\n",
      "  mean_raw_obs_processing_ms: 0.1221768006417737\n",
      "time_since_restore: 2977.8997242450714\n",
      "time_this_iter_s: 37.615928411483765\n",
      "time_total_s: 2977.8997242450714\n",
      "timers:\n",
      "  learn_throughput: 2128.408\n",
      "  learn_time_ms: 1879.339\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.999\n",
      "  sample_time_ms: 35714.69\n",
      "  update_time_ms: 1.903\n",
      "timestamp: 1633479598\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 316000\n",
      "training_iteration: 79\n",
      "\n",
      "agent_timesteps_total: 320000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-20-36\n",
      "done: false\n",
      "episode_len_mean: 794.76\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.48025227290809464\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 4\n",
      "episodes_total: 192\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.8954906463623047\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010382852517068386\n",
      "        model: {}\n",
      "        policy_loss: -0.011700691655278206\n",
      "        total_loss: -0.010795801877975464\n",
      "        vf_explained_var: -0.0351223386824131\n",
      "        vf_loss: 0.00012617322499863803\n",
      "  num_agent_steps_sampled: 320000\n",
      "  num_agent_steps_trained: 320000\n",
      "  num_steps_sampled: 320000\n",
      "  num_steps_trained: 320000\n",
      "iterations_since_restore: 80\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.758490566037736\n",
      "  ram_util_percent: 39.4245283018868\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0606370092010345\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.622194436374787\n",
      "  mean_inference_ms: 1.0768431635580205\n",
      "  mean_raw_obs_processing_ms: 0.12217416899345807\n",
      "time_since_restore: 3015.3916053771973\n",
      "time_this_iter_s: 37.491881132125854\n",
      "time_total_s: 3015.3916053771973\n",
      "timers:\n",
      "  learn_throughput: 2134.214\n",
      "  learn_time_ms: 1874.226\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.05\n",
      "  sample_time_ms: 35698.385\n",
      "  update_time_ms: 1.902\n",
      "timestamp: 1633479636\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 320000\n",
      "training_iteration: 80\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 324000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-21-13\n",
      "done: false\n",
      "episode_len_mean: 787.31\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.4772336572990039\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 195\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.0099931955337524\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01382405310869217\n",
      "        model: {}\n",
      "        policy_loss: -0.013898252509534359\n",
      "        total_loss: -0.012756247073411942\n",
      "        vf_explained_var: 0.08693724870681763\n",
      "        vf_loss: 0.00010520373325562105\n",
      "  num_agent_steps_sampled: 324000\n",
      "  num_agent_steps_trained: 324000\n",
      "  num_steps_sampled: 324000\n",
      "  num_steps_trained: 324000\n",
      "iterations_since_restore: 81\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.898076923076925\n",
      "  ram_util_percent: 39.43461538461539\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.060647461717983485\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.621942846955363\n",
      "  mean_inference_ms: 1.0768774210601806\n",
      "  mean_raw_obs_processing_ms: 0.1221740388904703\n",
      "time_since_restore: 3052.8870661258698\n",
      "time_this_iter_s: 37.495460748672485\n",
      "time_total_s: 3052.8870661258698\n",
      "timers:\n",
      "  learn_throughput: 2136.332\n",
      "  learn_time_ms: 1872.368\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.076\n",
      "  sample_time_ms: 35689.985\n",
      "  update_time_ms: 1.802\n",
      "timestamp: 1633479673\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 324000\n",
      "training_iteration: 81\n",
      "\n",
      "agent_timesteps_total: 328000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-21-51\n",
      "done: false\n",
      "episode_len_mean: 784.23\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.4742965047612033\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 198\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9070430397987366\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006406104192137718\n",
      "        model: {}\n",
      "        policy_loss: -0.008722134865820408\n",
      "        total_loss: -0.008147637359797955\n",
      "        vf_explained_var: 0.4223199188709259\n",
      "        vf_loss: 9.404305455973372e-05\n",
      "  num_agent_steps_sampled: 328000\n",
      "  num_agent_steps_trained: 328000\n",
      "  num_steps_sampled: 328000\n",
      "  num_steps_trained: 328000\n",
      "iterations_since_restore: 82\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.5\n",
      "  ram_util_percent: 39.44716981132075\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06065586089031081\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.6217323954364\n",
      "  mean_inference_ms: 1.076908630091129\n",
      "  mean_raw_obs_processing_ms: 0.1221750785732432\n",
      "time_since_restore: 3090.497503757477\n",
      "time_this_iter_s: 37.610437631607056\n",
      "time_total_s: 3090.497503757477\n",
      "timers:\n",
      "  learn_throughput: 2128.947\n",
      "  learn_time_ms: 1878.863\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.118\n",
      "  sample_time_ms: 35676.567\n",
      "  update_time_ms: 1.795\n",
      "timestamp: 1633479711\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 328000\n",
      "training_iteration: 82\n",
      "\n",
      "agent_timesteps_total: 332000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-22-29\n",
      "done: false\n",
      "episode_len_mean: 782.72\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.7695786860652079\n",
      "episode_reward_mean: -0.47403897548880813\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 200\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.8812623620033264\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010814237408339977\n",
      "        model: {}\n",
      "        policy_loss: -0.009932957589626312\n",
      "        total_loss: -0.009033058770000935\n",
      "        vf_explained_var: 0.39665260910987854\n",
      "        vf_loss: 8.883194095687941e-05\n",
      "  num_agent_steps_sampled: 332000\n",
      "  num_agent_steps_trained: 332000\n",
      "  num_steps_sampled: 332000\n",
      "  num_steps_trained: 332000\n",
      "iterations_since_restore: 83\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.186792452830186\n",
      "  ram_util_percent: 39.4301886792453\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0606651322385866\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.621587498418258\n",
      "  mean_inference_ms: 1.0769209484144946\n",
      "  mean_raw_obs_processing_ms: 0.1221772189512968\n",
      "time_since_restore: 3128.015299797058\n",
      "time_this_iter_s: 37.5177960395813\n",
      "time_total_s: 3128.015299797058\n",
      "timers:\n",
      "  learn_throughput: 2139.413\n",
      "  learn_time_ms: 1869.672\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.198\n",
      "  sample_time_ms: 35651.302\n",
      "  update_time_ms: 1.766\n",
      "timestamp: 1633479749\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 332000\n",
      "training_iteration: 83\n",
      "\n",
      "agent_timesteps_total: 336000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-23-06\n",
      "done: false\n",
      "episode_len_mean: 783.83\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.4551109509757514\n",
      "episode_reward_mean: -0.49569928511681965\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 202\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.8616787195205688\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010398704558610916\n",
      "        model: {}\n",
      "        policy_loss: -0.011356301605701447\n",
      "        total_loss: -0.010480324737727642\n",
      "        vf_explained_var: 0.08069636672735214\n",
      "        vf_loss: 9.606926323613152e-05\n",
      "  num_agent_steps_sampled: 336000\n",
      "  num_agent_steps_trained: 336000\n",
      "  num_steps_sampled: 336000\n",
      "  num_steps_trained: 336000\n",
      "iterations_since_restore: 84\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.962264150943398\n",
      "  ram_util_percent: 39.44716981132076\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.060670099588757916\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.621457614000573\n",
      "  mean_inference_ms: 1.076937814311612\n",
      "  mean_raw_obs_processing_ms: 0.1221776975209527\n",
      "time_since_restore: 3165.773410320282\n",
      "time_this_iter_s: 37.75811052322388\n",
      "time_total_s: 3165.773410320282\n",
      "timers:\n",
      "  learn_throughput: 2135.465\n",
      "  learn_time_ms: 1873.129\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.127\n",
      "  sample_time_ms: 35673.886\n",
      "  update_time_ms: 1.766\n",
      "timestamp: 1633479786\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 336000\n",
      "training_iteration: 84\n",
      "\n",
      "agent_timesteps_total: 340000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-23-44\n",
      "done: false\n",
      "episode_len_mean: 787.31\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.4551109509757514\n",
      "episode_reward_mean: -0.4875749852713185\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 204\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7542862296104431\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009573467075824738\n",
      "        model: {}\n",
      "        policy_loss: -0.014137663878500462\n",
      "        total_loss: -0.006757100112736225\n",
      "        vf_explained_var: -0.8324261903762817\n",
      "        vf_loss: 0.006662553176283836\n",
      "  num_agent_steps_sampled: 340000\n",
      "  num_agent_steps_trained: 340000\n",
      "  num_steps_sampled: 340000\n",
      "  num_steps_trained: 340000\n",
      "iterations_since_restore: 85\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.15094339622641\n",
      "  ram_util_percent: 39.464150943396234\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06067256649676016\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.621349284604516\n",
      "  mean_inference_ms: 1.076955121085069\n",
      "  mean_raw_obs_processing_ms: 0.12217703851856423\n",
      "time_since_restore: 3203.239823102951\n",
      "time_this_iter_s: 37.46641278266907\n",
      "time_total_s: 3203.239823102951\n",
      "timers:\n",
      "  learn_throughput: 2135.037\n",
      "  learn_time_ms: 1873.504\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.151\n",
      "  sample_time_ms: 35666.066\n",
      "  update_time_ms: 1.744\n",
      "timestamp: 1633479824\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 340000\n",
      "training_iteration: 85\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 344000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-24-21\n",
      "done: false\n",
      "episode_len_mean: 785.3\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.4551109509757514\n",
      "episode_reward_mean: -0.48489647545950443\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 207\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.734606921672821\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010679023340344429\n",
      "        model: {}\n",
      "        policy_loss: -0.015263883396983147\n",
      "        total_loss: -0.01393602043390274\n",
      "        vf_explained_var: -0.49570462107658386\n",
      "        vf_loss: 0.0005269380635581911\n",
      "  num_agent_steps_sampled: 344000\n",
      "  num_agent_steps_trained: 344000\n",
      "  num_steps_sampled: 344000\n",
      "  num_steps_trained: 344000\n",
      "iterations_since_restore: 86\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.286538461538463\n",
      "  ram_util_percent: 39.45192307692309\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06067666572092531\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.621199024716002\n",
      "  mean_inference_ms: 1.0769886244775984\n",
      "  mean_raw_obs_processing_ms: 0.12217249304999786\n",
      "time_since_restore: 3240.7881281375885\n",
      "time_this_iter_s: 37.54830503463745\n",
      "time_total_s: 3240.7881281375885\n",
      "timers:\n",
      "  learn_throughput: 2136.09\n",
      "  learn_time_ms: 1872.58\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.15\n",
      "  sample_time_ms: 35666.645\n",
      "  update_time_ms: 1.744\n",
      "timestamp: 1633479861\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 344000\n",
      "training_iteration: 86\n",
      "\n",
      "agent_timesteps_total: 348000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-24-59\n",
      "done: false\n",
      "episode_len_mean: 784.98\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.4551109509757514\n",
      "episode_reward_mean: -0.48523616255632573\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 209\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7792937159538269\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010706799104809761\n",
      "        model: {}\n",
      "        policy_loss: -0.01395124290138483\n",
      "        total_loss: -0.012911702506244183\n",
      "        vf_explained_var: 0.11970590800046921\n",
      "        vf_loss: 0.00023652741219848394\n",
      "  num_agent_steps_sampled: 348000\n",
      "  num_agent_steps_trained: 348000\n",
      "  num_steps_sampled: 348000\n",
      "  num_steps_trained: 348000\n",
      "iterations_since_restore: 87\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 28.18703703703704\n",
      "  ram_util_percent: 39.4388888888889\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.060677134402743554\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.62113240611707\n",
      "  mean_inference_ms: 1.0770147443725433\n",
      "  mean_raw_obs_processing_ms: 0.12216534144107224\n",
      "time_since_restore: 3278.5789453983307\n",
      "time_this_iter_s: 37.79081726074219\n",
      "time_total_s: 3278.5789453983307\n",
      "timers:\n",
      "  learn_throughput: 2131.183\n",
      "  learn_time_ms: 1876.892\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.044\n",
      "  sample_time_ms: 35700.392\n",
      "  update_time_ms: 1.745\n",
      "timestamp: 1633479899\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 348000\n",
      "training_iteration: 87\n",
      "\n",
      "agent_timesteps_total: 352000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-25-37\n",
      "done: false\n",
      "episode_len_mean: 785.76\n",
      "episode_media: {}\n",
      "episode_reward_max: 1.4551109509757514\n",
      "episode_reward_mean: -0.4841356630652563\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 211\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7623973488807678\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006906263064593077\n",
      "        model: {}\n",
      "        policy_loss: -0.004714693874120712\n",
      "        total_loss: -0.004054793622344732\n",
      "        vf_explained_var: 0.057320885360240936\n",
      "        vf_loss: 0.0001419248728780076\n",
      "  num_agent_steps_sampled: 352000\n",
      "  num_agent_steps_trained: 352000\n",
      "  num_steps_sampled: 352000\n",
      "  num_steps_trained: 352000\n",
      "iterations_since_restore: 88\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.559615384615384\n",
      "  ram_util_percent: 39.46923076923077\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06067574614591848\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.62105885699023\n",
      "  mean_inference_ms: 1.077040825303396\n",
      "  mean_raw_obs_processing_ms: 0.12215620735816039\n",
      "time_since_restore: 3316.092843055725\n",
      "time_this_iter_s: 37.51389765739441\n",
      "time_total_s: 3316.092843055725\n",
      "timers:\n",
      "  learn_throughput: 2129.729\n",
      "  learn_time_ms: 1878.174\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.06\n",
      "  sample_time_ms: 35695.117\n",
      "  update_time_ms: 1.745\n",
      "timestamp: 1633479937\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 352000\n",
      "training_iteration: 88\n",
      "\n",
      "agent_timesteps_total: 356000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-26-14\n",
      "done: false\n",
      "episode_len_mean: 788.01\n",
      "episode_media: {}\n",
      "episode_reward_max: 0.5742139574910281\n",
      "episode_reward_mean: -0.5057967524102891\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 213\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.80893474817276\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016390271484851837\n",
      "        model: {}\n",
      "        policy_loss: -0.01779250055551529\n",
      "        total_loss: -0.01643235981464386\n",
      "        vf_explained_var: 0.03914457932114601\n",
      "        vf_loss: 0.0001308722421526909\n",
      "  num_agent_steps_sampled: 356000\n",
      "  num_agent_steps_trained: 356000\n",
      "  num_steps_sampled: 356000\n",
      "  num_steps_trained: 356000\n",
      "iterations_since_restore: 89\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.08490566037735\n",
      "  ram_util_percent: 39.4622641509434\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06067261618766285\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.621006705845772\n",
      "  mean_inference_ms: 1.077068292409879\n",
      "  mean_raw_obs_processing_ms: 0.122141936169192\n",
      "time_since_restore: 3353.774313211441\n",
      "time_this_iter_s: 37.68147015571594\n",
      "time_total_s: 3353.774313211441\n",
      "timers:\n",
      "  learn_throughput: 2130.636\n",
      "  learn_time_ms: 1877.374\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.037\n",
      "  sample_time_ms: 35702.436\n",
      "  update_time_ms: 1.845\n",
      "timestamp: 1633479974\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 356000\n",
      "training_iteration: 89\n",
      "\n",
      "agent_timesteps_total: 360000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-26-52\n",
      "done: false\n",
      "episode_len_mean: 797.26\n",
      "episode_media: {}\n",
      "episode_reward_max: 0.5742139574910281\n",
      "episode_reward_mean: -0.5105506664378229\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 216\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7217498421669006\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008696525357663631\n",
      "        model: {}\n",
      "        policy_loss: -0.014598581939935684\n",
      "        total_loss: -0.013828040100634098\n",
      "        vf_explained_var: 0.10099340975284576\n",
      "        vf_loss: 0.00011829929280793294\n",
      "  num_agent_steps_sampled: 360000\n",
      "  num_agent_steps_trained: 360000\n",
      "  num_steps_sampled: 360000\n",
      "  num_steps_trained: 360000\n",
      "iterations_since_restore: 90\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.701886792452832\n",
      "  ram_util_percent: 39.469811320754715\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.060664426385942834\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.62094616028754\n",
      "  mean_inference_ms: 1.0771132735627387\n",
      "  mean_raw_obs_processing_ms: 0.12212100325579128\n",
      "time_since_restore: 3391.5263867378235\n",
      "time_this_iter_s: 37.752073526382446\n",
      "time_total_s: 3391.5263867378235\n",
      "timers:\n",
      "  learn_throughput: 2113.143\n",
      "  learn_time_ms: 1892.915\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.005\n",
      "  sample_time_ms: 35712.758\n",
      "  update_time_ms: 1.845\n",
      "timestamp: 1633480012\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 360000\n",
      "training_iteration: 90\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 364000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-27-30\n",
      "done: false\n",
      "episode_len_mean: 795.83\n",
      "episode_media: {}\n",
      "episode_reward_max: 0.5742139574910281\n",
      "episode_reward_mean: -0.5092795503928776\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 218\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.8348459601402283\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00968570914119482\n",
      "        model: {}\n",
      "        policy_loss: -0.009951277635991573\n",
      "        total_loss: -0.009093190543353558\n",
      "        vf_explained_var: 0.34426406025886536\n",
      "        vf_loss: 0.0001316604611929506\n",
      "  num_agent_steps_sampled: 364000\n",
      "  num_agent_steps_trained: 364000\n",
      "  num_steps_sampled: 364000\n",
      "  num_steps_trained: 364000\n",
      "iterations_since_restore: 91\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.215094339622638\n",
      "  ram_util_percent: 39.484905660377365\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06065752524541833\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.620916103047474\n",
      "  mean_inference_ms: 1.0771442462938998\n",
      "  mean_raw_obs_processing_ms: 0.12210151688069205\n",
      "time_since_restore: 3428.9972155094147\n",
      "time_this_iter_s: 37.47082877159119\n",
      "time_total_s: 3428.9972155094147\n",
      "timers:\n",
      "  learn_throughput: 2112.764\n",
      "  learn_time_ms: 1893.255\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 112.013\n",
      "  sample_time_ms: 35709.993\n",
      "  update_time_ms: 1.946\n",
      "timestamp: 1633480050\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 364000\n",
      "training_iteration: 91\n",
      "\n",
      "agent_timesteps_total: 368000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-28-08\n",
      "done: false\n",
      "episode_len_mean: 793.53\n",
      "episode_media: {}\n",
      "episode_reward_max: 0.5742139574910281\n",
      "episode_reward_mean: -0.5090853231226427\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 221\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6444706320762634\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010874904692173004\n",
      "        model: {}\n",
      "        policy_loss: -0.01339687779545784\n",
      "        total_loss: -0.012519092299044132\n",
      "        vf_explained_var: 0.2776297926902771\n",
      "        vf_loss: 6.216790643520653e-05\n",
      "  num_agent_steps_sampled: 368000\n",
      "  num_agent_steps_trained: 368000\n",
      "  num_steps_sampled: 368000\n",
      "  num_steps_trained: 368000\n",
      "iterations_since_restore: 92\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.337037037037035\n",
      "  ram_util_percent: 39.585185185185175\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.060653249339580766\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.62096500867161\n",
      "  mean_inference_ms: 1.077191388569266\n",
      "  mean_raw_obs_processing_ms: 0.12207425895364979\n",
      "time_since_restore: 3467.2766828536987\n",
      "time_this_iter_s: 38.27946734428406\n",
      "time_total_s: 3467.2766828536987\n",
      "timers:\n",
      "  learn_throughput: 2112.816\n",
      "  learn_time_ms: 1893.208\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.803\n",
      "  sample_time_ms: 35777.07\n",
      "  update_time_ms: 1.928\n",
      "timestamp: 1633480088\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 368000\n",
      "training_iteration: 92\n",
      "\n",
      "agent_timesteps_total: 372000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-28-46\n",
      "done: false\n",
      "episode_len_mean: 794.48\n",
      "episode_media: {}\n",
      "episode_reward_max: 0.5742139574910281\n",
      "episode_reward_mean: -0.5070542072043632\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 223\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7957772612571716\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012777352705597878\n",
      "        model: {}\n",
      "        policy_loss: -0.013709774240851402\n",
      "        total_loss: -0.012695802375674248\n",
      "        vf_explained_var: 0.05017254874110222\n",
      "        vf_loss: 5.5666685511823744e-05\n",
      "  num_agent_steps_sampled: 372000\n",
      "  num_agent_steps_trained: 372000\n",
      "  num_steps_sampled: 372000\n",
      "  num_steps_trained: 372000\n",
      "iterations_since_restore: 93\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.583018867924526\n",
      "  ram_util_percent: 39.60754716981131\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06064866400554934\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.620824043719523\n",
      "  mean_inference_ms: 1.0772078356381842\n",
      "  mean_raw_obs_processing_ms: 0.12205965579785018\n",
      "time_since_restore: 3505.102270126343\n",
      "time_this_iter_s: 37.82558727264404\n",
      "time_total_s: 3505.102270126343\n",
      "timers:\n",
      "  learn_throughput: 2113.091\n",
      "  learn_time_ms: 1892.961\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.706\n",
      "  sample_time_ms: 35808.173\n",
      "  update_time_ms: 1.957\n",
      "timestamp: 1633480126\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 372000\n",
      "training_iteration: 93\n",
      "\n",
      "agent_timesteps_total: 376000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-29-23\n",
      "done: false\n",
      "episode_len_mean: 788.81\n",
      "episode_media: {}\n",
      "episode_reward_max: 0.397136955295059\n",
      "episode_reward_mean: -0.5136658323452934\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 226\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7541139125823975\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007502318359911442\n",
      "        model: {}\n",
      "        policy_loss: -0.016288697719573975\n",
      "        total_loss: -0.015624353662133217\n",
      "        vf_explained_var: 0.3851321041584015\n",
      "        vf_loss: 0.00010166996798943728\n",
      "  num_agent_steps_sampled: 376000\n",
      "  num_agent_steps_trained: 376000\n",
      "  num_steps_sampled: 376000\n",
      "  num_steps_trained: 376000\n",
      "iterations_since_restore: 94\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.63018867924528\n",
      "  ram_util_percent: 39.58301886792452\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06063504067237073\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.620188125180384\n",
      "  mean_inference_ms: 1.0772057370769375\n",
      "  mean_raw_obs_processing_ms: 0.12203413665940915\n",
      "time_since_restore: 3542.6752710342407\n",
      "time_this_iter_s: 37.57300090789795\n",
      "time_total_s: 3542.6752710342407\n",
      "timers:\n",
      "  learn_throughput: 2107.338\n",
      "  learn_time_ms: 1898.129\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.78\n",
      "  sample_time_ms: 35784.567\n",
      "  update_time_ms: 1.857\n",
      "timestamp: 1633480163\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 376000\n",
      "training_iteration: 94\n",
      "\n",
      "agent_timesteps_total: 380000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-30-01\n",
      "done: false\n",
      "episode_len_mean: 785.9\n",
      "episode_media: {}\n",
      "episode_reward_max: 0.397136955295059\n",
      "episode_reward_mean: -0.5123673610209584\n",
      "episode_reward_min: -0.8542991464031026\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 228\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5716546177864075\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007822458632290363\n",
      "        model: {}\n",
      "        policy_loss: -0.012409370392560959\n",
      "        total_loss: -0.011737753637135029\n",
      "        vf_explained_var: 0.2736261487007141\n",
      "        vf_loss: 8.493009954690933e-05\n",
      "  num_agent_steps_sampled: 380000\n",
      "  num_agent_steps_trained: 380000\n",
      "  num_steps_sampled: 380000\n",
      "  num_steps_trained: 380000\n",
      "iterations_since_restore: 95\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.375471698113206\n",
      "  ram_util_percent: 39.55094339622641\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06062561724778024\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.61966992046632\n",
      "  mean_inference_ms: 1.0772010694370868\n",
      "  mean_raw_obs_processing_ms: 0.12201943471104673\n",
      "time_since_restore: 3580.327555179596\n",
      "time_this_iter_s: 37.652284145355225\n",
      "time_total_s: 3580.327555179596\n",
      "timers:\n",
      "  learn_throughput: 2104.373\n",
      "  learn_time_ms: 1900.804\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.73\n",
      "  sample_time_ms: 35800.542\n",
      "  update_time_ms: 1.879\n",
      "timestamp: 1633480201\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 380000\n",
      "training_iteration: 95\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 384000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-30-39\n",
      "done: false\n",
      "episode_len_mean: 788.79\n",
      "episode_media: {}\n",
      "episode_reward_max: 0.36438407137707773\n",
      "episode_reward_mean: -0.5231457828380506\n",
      "episode_reward_min: -0.8230728291462255\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 231\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7382208704948425\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006780384574085474\n",
      "        model: {}\n",
      "        policy_loss: -0.01328427717089653\n",
      "        total_loss: -0.012717376463115215\n",
      "        vf_explained_var: 0.24072879552841187\n",
      "        vf_loss: 5.837141361553222e-05\n",
      "  num_agent_steps_sampled: 384000\n",
      "  num_agent_steps_trained: 384000\n",
      "  num_steps_sampled: 384000\n",
      "  num_steps_trained: 384000\n",
      "iterations_since_restore: 96\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.09433962264151\n",
      "  ram_util_percent: 39.51509433962264\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.060616953836042355\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.61895080483167\n",
      "  mean_inference_ms: 1.0771878955192864\n",
      "  mean_raw_obs_processing_ms: 0.12200169772301284\n",
      "time_since_restore: 3617.9981956481934\n",
      "time_this_iter_s: 37.67064046859741\n",
      "time_total_s: 3617.9981956481934\n",
      "timers:\n",
      "  learn_throughput: 2098.034\n",
      "  learn_time_ms: 1906.547\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.71\n",
      "  sample_time_ms: 35807.05\n",
      "  update_time_ms: 1.88\n",
      "timestamp: 1633480239\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 384000\n",
      "training_iteration: 96\n",
      "\n",
      "agent_timesteps_total: 388000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-31-16\n",
      "done: false\n",
      "episode_len_mean: 786.79\n",
      "episode_media: {}\n",
      "episode_reward_max: 0.36438407137707773\n",
      "episode_reward_mean: -0.5234430708051048\n",
      "episode_reward_min: -0.8230728291462255\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 233\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6531770825386047\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00790418777614832\n",
      "        model: {}\n",
      "        policy_loss: -0.013025304302573204\n",
      "        total_loss: -0.012379025109112263\n",
      "        vf_explained_var: 0.39340755343437195\n",
      "        vf_loss: 5.3463932999875396e-05\n",
      "  num_agent_steps_sampled: 388000\n",
      "  num_agent_steps_trained: 388000\n",
      "  num_steps_sampled: 388000\n",
      "  num_steps_trained: 388000\n",
      "iterations_since_restore: 97\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.051923076923075\n",
      "  ram_util_percent: 39.51538461538462\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06061011051087714\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.61848731865831\n",
      "  mean_inference_ms: 1.0771796098754443\n",
      "  mean_raw_obs_processing_ms: 0.12198825611576215\n",
      "time_since_restore: 3655.5197763442993\n",
      "time_this_iter_s: 37.52158069610596\n",
      "time_total_s: 3655.5197763442993\n",
      "timers:\n",
      "  learn_throughput: 2106.384\n",
      "  learn_time_ms: 1898.989\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.77\n",
      "  sample_time_ms: 35787.711\n",
      "  update_time_ms: 1.949\n",
      "timestamp: 1633480276\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 388000\n",
      "training_iteration: 97\n",
      "\n",
      "agent_timesteps_total: 392000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-31-54\n",
      "done: false\n",
      "episode_len_mean: 784.99\n",
      "episode_media: {}\n",
      "episode_reward_max: 0.36438407137707773\n",
      "episode_reward_mean: -0.5208950165043807\n",
      "episode_reward_min: -0.8230728291462255\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 235\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6763270497322083\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012279213406145573\n",
      "        model: {}\n",
      "        policy_loss: -0.015760788694024086\n",
      "        total_loss: -0.01477763056755066\n",
      "        vf_explained_var: 0.39891842007637024\n",
      "        vf_loss: 6.222207593964413e-05\n",
      "  num_agent_steps_sampled: 392000\n",
      "  num_agent_steps_trained: 392000\n",
      "  num_steps_sampled: 392000\n",
      "  num_steps_trained: 392000\n",
      "iterations_since_restore: 98\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.166037735849056\n",
      "  ram_util_percent: 39.516981132075465\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06060304084517146\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.61804303551046\n",
      "  mean_inference_ms: 1.0771758741955773\n",
      "  mean_raw_obs_processing_ms: 0.12197418722783177\n",
      "time_since_restore: 3693.073881626129\n",
      "time_this_iter_s: 37.554105281829834\n",
      "time_total_s: 3693.073881626129\n",
      "timers:\n",
      "  learn_throughput: 2106.658\n",
      "  learn_time_ms: 1898.742\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.757\n",
      "  sample_time_ms: 35792.025\n",
      "  update_time_ms: 1.934\n",
      "timestamp: 1633480314\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 392000\n",
      "training_iteration: 98\n",
      "\n",
      "agent_timesteps_total: 396000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-32-31\n",
      "done: false\n",
      "episode_len_mean: 788.04\n",
      "episode_media: {}\n",
      "episode_reward_max: 0.36438407137707773\n",
      "episode_reward_mean: -0.5191128930427943\n",
      "episode_reward_min: -0.8230728291462255\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 238\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6928106546401978\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011421173810958862\n",
      "        model: {}\n",
      "        policy_loss: -0.012882143259048462\n",
      "        total_loss: -0.011943407356739044\n",
      "        vf_explained_var: 0.11697831004858017\n",
      "        vf_loss: 8.214814442908391e-05\n",
      "  num_agent_steps_sampled: 396000\n",
      "  num_agent_steps_trained: 396000\n",
      "  num_steps_sampled: 396000\n",
      "  num_steps_trained: 396000\n",
      "iterations_since_restore: 99\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.516981132075472\n",
      "  ram_util_percent: 39.516981132075465\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06058843093210736\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.61739133601363\n",
      "  mean_inference_ms: 1.0771743051890605\n",
      "  mean_raw_obs_processing_ms: 0.1219505010282011\n",
      "time_since_restore: 3730.6299271583557\n",
      "time_this_iter_s: 37.55604553222656\n",
      "time_total_s: 3730.6299271583557\n",
      "timers:\n",
      "  learn_throughput: 2104.394\n",
      "  learn_time_ms: 1900.785\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.802\n",
      "  sample_time_ms: 35777.389\n",
      "  update_time_ms: 1.933\n",
      "timestamp: 1633480351\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 396000\n",
      "training_iteration: 99\n",
      "\n",
      "agent_timesteps_total: 400000\n",
      "custom_metrics: {}\n",
      "date: 2021-10-06_09-33-09\n",
      "done: false\n",
      "episode_len_mean: 784.92\n",
      "episode_media: {}\n",
      "episode_reward_max: 0.36438407137707773\n",
      "episode_reward_mean: -0.517212226679088\n",
      "episode_reward_min: -0.8230728291462255\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 240\n",
      "experiment_id: 3ef6a5abca4b49a7a6d35542aefb3c40\n",
      "hostname: DESKTOP\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5681696534156799\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007380861323326826\n",
      "        model: {}\n",
      "        policy_loss: -0.007493722718209028\n",
      "        total_loss: -0.006855115760117769\n",
      "        vf_explained_var: -0.09710268676280975\n",
      "        vf_loss: 8.5042993305251e-05\n",
      "  num_agent_steps_sampled: 400000\n",
      "  num_agent_steps_trained: 400000\n",
      "  num_steps_sampled: 400000\n",
      "  num_steps_trained: 400000\n",
      "iterations_since_restore: 100\n",
      "node_ip: 192.168.0.196\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 26.2377358490566\n",
      "  ram_util_percent: 39.52830188679244\n",
      "pid: 268\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06058060394718428\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 16.61699613833717\n",
      "  mean_inference_ms: 1.0771717349684178\n",
      "  mean_raw_obs_processing_ms: 0.1219297991658297\n",
      "time_since_restore: 3768.138795852661\n",
      "time_this_iter_s: 37.50886869430542\n",
      "time_total_s: 3768.138795852661\n",
      "timers:\n",
      "  learn_throughput: 2122.213\n",
      "  learn_time_ms: 1884.825\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_throughput: 111.828\n",
      "  sample_time_ms: 35769.126\n",
      "  update_time_ms: 1.833\n",
      "timestamp: 1633480389\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 400000\n",
      "training_iteration: 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "for _ in range(100):\n",
    "    r = trainer.train()\n",
    "    print(pretty_print(r))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Takumi/ray_results\\\\PPO_MyEnv_2021-10-06_08-30-12w281e8zv\\\\checkpoint_000100\\\\checkpoint-100'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = trainer.save()\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-06 10:50:26,831\tINFO trainable.py:383 -- Restored on 192.168.0.196 from checkpoint: C:\\Users\\Takumi/ray_results\\PPO_MyEnv_2021-10-06_08-30-12w281e8zv\\checkpoint_000100\\checkpoint-100\n",
      "2021-10-06 10:50:26,832\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 3768.138795852661, '_episodes_total': 240}\n"
     ]
    }
   ],
   "source": [
    "trainer.restore(checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
